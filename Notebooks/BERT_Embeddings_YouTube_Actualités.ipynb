{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Embeddings YouTube Actualités.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UnmmKK6dO4Ic",
        "NaOBkKr5O4j8",
        "1ow9wNsVYQ-P"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "028a14d9e57b48c1965c75481fef7fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca04293b807a4028b4f7ad0ace68d56d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08b8d47c18c244d8850d541af40b37c7",
              "IPY_MODEL_843031c181ce4a84b6a49e3bea1cf0e0"
            ]
          }
        },
        "ca04293b807a4028b4f7ad0ace68d56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08b8d47c18c244d8850d541af40b37c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b64b9c26d5148bf9086a2aa8afdcdbf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8b4180904c648f480ac301a092cae69"
          }
        },
        "843031c181ce4a84b6a49e3bea1cf0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bd19d6e7b4641deaf793e37078ee186",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 2.22kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3819e3f3835b4f09afaa3ae5611218af"
          }
        },
        "4b64b9c26d5148bf9086a2aa8afdcdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8b4180904c648f480ac301a092cae69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bd19d6e7b4641deaf793e37078ee186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3819e3f3835b4f09afaa3ae5611218af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acc320f8126c4e58991ecb006f297089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48654baac81c43bcbb5b8d13b578a0fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10148cfa476d4671b0601a5dc62e61a6",
              "IPY_MODEL_4c570d0dcf3e494480d8cc7543daa1e2"
            ]
          }
        },
        "48654baac81c43bcbb5b8d13b578a0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10148cfa476d4671b0601a5dc62e61a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6dab9da68b248ba8b8f2842df14588d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1562605,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1562605,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c131b6e82b2744ceb91a4108de2ea80c"
          }
        },
        "4c570d0dcf3e494480d8cc7543daa1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7dd3530cc1954674a4e9a147153dc7f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.56M/1.56M [00:00&lt;00:00, 5.45MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7402b6ec36e43a2aa5803048c712239"
          }
        },
        "c6dab9da68b248ba8b8f2842df14588d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c131b6e82b2744ceb91a4108de2ea80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dd3530cc1954674a4e9a147153dc7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7402b6ec36e43a2aa5803048c712239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebdab49507984fe088964f4c5f34120d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05508bbb811f46d586db88f4f183ec5a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c959f6b788264b2faa8dbc5f8421cced",
              "IPY_MODEL_37e073730d554a1d979a2a72daff5f24"
            ]
          }
        },
        "05508bbb811f46d586db88f4f183ec5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c959f6b788264b2faa8dbc5f8421cced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_822e890c48944065985ae2e97c5049da",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917147,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917147,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d08b1856be34cd38ce8a4fb4c400486"
          }
        },
        "37e073730d554a1d979a2a72daff5f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b42c3494b534d578e0af3513ed5a07d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917k/917k [00:00&lt;00:00, 4.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4f346e1acb64889b0781046fdbb165c"
          }
        },
        "822e890c48944065985ae2e97c5049da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d08b1856be34cd38ce8a4fb4c400486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b42c3494b534d578e0af3513ed5a07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4f346e1acb64889b0781046fdbb165c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc17843704534910a2b0b7221e5e5c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b6f8286671a24de59cf2a09ce46aa82a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8ac3025e5544a47a594371801d02995",
              "IPY_MODEL_dd4ab823aa3e49ca95916f92d128ee93"
            ]
          }
        },
        "b6f8286671a24de59cf2a09ce46aa82a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8ac3025e5544a47a594371801d02995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_029342997d104e588cd760c8d0e04ca4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 549587475,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 549587475,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ece74cb65acd4587a98183693bc8a032"
          }
        },
        "dd4ab823aa3e49ca95916f92d128ee93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68f081be7e1b44a5adf244f754613575",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 550M/550M [00:18&lt;00:00, 29.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9f7e080dce74ee2b0d29d06f3b6e9eb"
          }
        },
        "029342997d104e588cd760c8d0e04ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ece74cb65acd4587a98183693bc8a032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68f081be7e1b44a5adf244f754613575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9f7e080dce74ee2b0d29d06f3b6e9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8829aa9d5aa4daaaa443bdae59ee6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45c2372936504c72b688bdce21fac490",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a67931399444cc2994feceb78e65230",
              "IPY_MODEL_b3c2db76eb054b36acf88dba83606d20"
            ]
          }
        },
        "45c2372936504c72b688bdce21fac490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a67931399444cc2994feceb78e65230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34d8c51980154aba89a9ee39546b9555",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77429a46194f4e9e842e7882d0bcfc49"
          }
        },
        "b3c2db76eb054b36acf88dba83606d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52fcb9d0125940f7b38b76856aabf1a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 2.34kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0348447da944e289abdbf9e06d9d1b5"
          }
        },
        "34d8c51980154aba89a9ee39546b9555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77429a46194f4e9e842e7882d0bcfc49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52fcb9d0125940f7b38b76856aabf1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0348447da944e289abdbf9e06d9d1b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2dbd442a7f364bea97385bcf828610a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50b847f64d8e4088a11c41cf00c576e2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d91e63f7ed98475ca9fa500eafc9c6f6",
              "IPY_MODEL_d4a14f9629c64bbc838f050b6e3665a6"
            ]
          }
        },
        "50b847f64d8e4088a11c41cf00c576e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d91e63f7ed98475ca9fa500eafc9c6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b5b42595fa64d0ebdb0876fec70c78d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1562605,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1562605,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_285bc3c944a947c782d530dff99c5809"
          }
        },
        "d4a14f9629c64bbc838f050b6e3665a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8764e353b6ad49cabcfccf1959108b22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.56M/1.56M [00:00&lt;00:00, 6.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04ba12c14ca64d5fbdf5a28ca3fd273b"
          }
        },
        "0b5b42595fa64d0ebdb0876fec70c78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "285bc3c944a947c782d530dff99c5809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8764e353b6ad49cabcfccf1959108b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04ba12c14ca64d5fbdf5a28ca3fd273b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c4c2bc619524cb184f96410877f889a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fae150f505384f9a983617284142915f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d0bc29403ae4c6d815317a20c14ba16",
              "IPY_MODEL_fd2732adec5a4ae3bf62e65614e37e72"
            ]
          }
        },
        "fae150f505384f9a983617284142915f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d0bc29403ae4c6d815317a20c14ba16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecd55764c2d341fc8c33341262926bb1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917147,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917147,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e9e828f68bd4aea81608ed8c5a40af0"
          }
        },
        "fd2732adec5a4ae3bf62e65614e37e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b13983e5aef84feba0a1a57885c78b69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917k/917k [00:00&lt;00:00, 4.93MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02337d4f2b7e4945b4922fdd40bdb95c"
          }
        },
        "ecd55764c2d341fc8c33341262926bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e9e828f68bd4aea81608ed8c5a40af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b13983e5aef84feba0a1a57885c78b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02337d4f2b7e4945b4922fdd40bdb95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2696d9487a5e492bbb637f7d563a1ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f93492a33a61450f8208e50be98c1355",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe4d427b3bf146cd87f3b7d15fb58eac",
              "IPY_MODEL_b3fe3ea760774944b93d00154101042a"
            ]
          }
        },
        "f93492a33a61450f8208e50be98c1355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe4d427b3bf146cd87f3b7d15fb58eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7af0a3e2d769436f98e41182212b893c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e229b20f9b44925a3fe35edbcec212f"
          }
        },
        "b3fe3ea760774944b93d00154101042a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1653d70e4a6f497cbb90ec4ce79fce51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00, 12.21ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dec0abcb82394b339187e907a63d6dbf"
          }
        },
        "7af0a3e2d769436f98e41182212b893c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e229b20f9b44925a3fe35edbcec212f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1653d70e4a6f497cbb90ec4ce79fce51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dec0abcb82394b339187e907a63d6dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "679738b08cd646f2be45916ec228831a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aee63e358c1b46b0ba1bdffd43169e96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ac2eaa29f714ac18800117139004f04",
              "IPY_MODEL_975c68c690c04f61b68509e436cfa879"
            ]
          }
        },
        "aee63e358c1b46b0ba1bdffd43169e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ac2eaa29f714ac18800117139004f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a03ac03d8cb84c1e976afef7c870eadf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01e12301790e438986c0a4208887ce56"
          }
        },
        "975c68c690c04f61b68509e436cfa879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_580bb01aab2b47a087f513437853ef88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:02&lt;00:00,  2.49s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f89bf83d12f4acd8eed3e10e66284e4"
          }
        },
        "a03ac03d8cb84c1e976afef7c870eadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01e12301790e438986c0a4208887ce56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "580bb01aab2b47a087f513437853ef88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f89bf83d12f4acd8eed3e10e66284e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e457c451a24d42bd8172d682b262a833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dbbd15ed92f4e528baa4cdb8893f88e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab2e57f2e9fc424fae860b10a2986b1c",
              "IPY_MODEL_2214b698a79f4cbebb85098598b7cee3"
            ]
          }
        },
        "8dbbd15ed92f4e528baa4cdb8893f88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab2e57f2e9fc424fae860b10a2986b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_928d0f10704c408fa70afc322e719dd4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb9a5825db964e04937184bd06432e47"
          }
        },
        "2214b698a79f4cbebb85098598b7cee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_061eae2742be4eae94c4bf2df3a7f6ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.50k/1.50k [01:04&lt;00:00, 23.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36a1e82badce4b9c8357d0da958a6424"
          }
        },
        "928d0f10704c408fa70afc322e719dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb9a5825db964e04937184bd06432e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "061eae2742be4eae94c4bf2df3a7f6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36a1e82badce4b9c8357d0da958a6424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "385719e2186145c99b68754eec71ae7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2683be894544a06a1e9014318c6dd08",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81739e24978d45528d817b7b64fb3963",
              "IPY_MODEL_3260b22faa3f4b0f9e04f2f746434862"
            ]
          }
        },
        "a2683be894544a06a1e9014318c6dd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81739e24978d45528d817b7b64fb3963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd9f1b9fcf0e497999fdc645005db057",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1562605,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1562605,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc216a4166b44b8b8d70fb77d1533a88"
          }
        },
        "3260b22faa3f4b0f9e04f2f746434862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4758fc0e80f14e3b81bf52fa7309cabf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.56M/1.56M [00:01&lt;00:00, 1.49MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faa82179f78c431da830d296414aae69"
          }
        },
        "cd9f1b9fcf0e497999fdc645005db057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc216a4166b44b8b8d70fb77d1533a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4758fc0e80f14e3b81bf52fa7309cabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faa82179f78c431da830d296414aae69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f51fb6a95aab4641bea758265431c899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5f2981d4953431fbf1a4fe1419d3d4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f530c6b97c244d04bed199c514381e2e",
              "IPY_MODEL_91eafd446b9d40808a9b5482c01c495d"
            ]
          }
        },
        "e5f2981d4953431fbf1a4fe1419d3d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f530c6b97c244d04bed199c514381e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf8115eb2e7e49e887bf8421d9906444",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 917147,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 917147,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebde16e32f3a490f9c25b0066522a415"
          }
        },
        "91eafd446b9d40808a9b5482c01c495d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85f8b06fb08b488e9846a63536021217",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 917k/917k [00:00&lt;00:00, 1.52MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9185edad3bec473f9544e9d78b495de2"
          }
        },
        "cf8115eb2e7e49e887bf8421d9906444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebde16e32f3a490f9c25b0066522a415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85f8b06fb08b488e9846a63536021217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9185edad3bec473f9544e9d78b495de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d373def94fd44e4bb5139d0ab242410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55e3d0ff02df49fcb82a416fc1ba234b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f9a01ce3ca84ff19e0c245ecb3909a5",
              "IPY_MODEL_263ba2e2a4c0479886b1c14b309a5665"
            ]
          }
        },
        "55e3d0ff02df49fcb82a416fc1ba234b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f9a01ce3ca84ff19e0c245ecb3909a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3baaedf56c9450abedf0c2e0b3a2a77",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 27,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 27,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_071482cab354414a936f541378054a53"
          }
        },
        "263ba2e2a4c0479886b1c14b309a5665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4feb1a89d6fd43b9a694de015a0eecc3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 27.0/27.0 [00:00&lt;00:00, 106B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13fd87a51f8c44d9a8af82b2d870e71d"
          }
        },
        "e3baaedf56c9450abedf0c2e0b3a2a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "071482cab354414a936f541378054a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4feb1a89d6fd43b9a694de015a0eecc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13fd87a51f8c44d9a8af82b2d870e71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVyU15LHeYdC"
      },
      "source": [
        "## BERT embeddings pour l'analyse textuelle \n",
        "#### Utilisation de la librairie Hugging Face\n",
        "- 1) exploration du contenu d'un modèle BERT (français)\n",
        "- 2) réglage fin d'un modèle BERT français sur notre corpus\n",
        "- 3) clustering de documents et topics dérivés (à la Bertopic)\n",
        "- 4) topics comme clustering de (sens de) tokens (à faire) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwbbmEfUgvpU"
      },
      "source": [
        "##### Installation des librairies HuggingFace non installées par défaut dans Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZKSFPUQslJT",
        "outputId": "e664c78a-1e95-480c-9a57-0c136d3f5870"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/73/742d17d8a9a1c639132affccc9250f0743e484cbf263ede6ddcbe34ef212/datasets-1.4.1-py3-none-any.whl (186kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 102kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 112kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 122kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 133kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 143kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 153kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 163kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 174kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 184kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/93/7cb0755c62c36cdadc70c79a95681df685b52cbaf76c724facb6ecac3272/huggingface_hub-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.6MB/s \n",
            "\u001b[?25hCollecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: huggingface-hub, xxhash, fsspec, datasets\n",
            "Successfully installed datasets-1.4.1 fsspec-0.8.7 huggingface-hub-0.0.2 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfpIfQQGsltw",
        "outputId": "627798b7-9d4f-47d6-937d-67a4209bea3d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/d8/5144b0712f7f82229a8da5983a8fbb8d30cec5fbd5f8d12ffe1854dcea67/transformers-4.4.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=f80da26e5c4d13769a2a5a8dbe4a02958c1830714bde9b9fdc109eb13fad3bb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw7Akn1RFzH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d0c1d1-6174-4de5-fe77-0b18367b2ef4"
      },
      "source": [
        "# pour sauvegarder un graphique spacy sous forme de fichier\n",
        "!pip install plotly==4.7.1\n",
        "!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "!chmod +x /usr/local/bin/orca\n",
        "!apt-get install xvfb libgtk2.0-0 libgconf-2-4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly==4.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/78/eb6cbe96c8379c54819592bb228c58ed7386fcc60a55eca7db99432fdf14/plotly-4.7.1-py2.py3-none-any.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5MB 339kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==4.7.1) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly==4.7.1) (1.3.3)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed plotly-4.7.1\n",
            "--2021-03-17 11:54:29--  https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210317%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210317T115429Z&X-Amz-Expires=300&X-Amz-Signature=051601889547ec6cded9bd51af84f43c75c7122cd9fdd238480d7b26ba3523ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=99037241&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-03-17 11:54:29--  https://github-releases.githubusercontent.com/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210317%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210317T115429Z&X-Amz-Expires=300&X-Amz-Signature=051601889547ec6cded9bd51af84f43c75c7122cd9fdd238480d7b26ba3523ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=99037241&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.110.154, 185.199.109.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51607939 (49M) [application/octet-stream]\n",
            "Saving to: ‘/usr/local/bin/orca’\n",
            "\n",
            "/usr/local/bin/orca 100%[===================>]  49.22M  84.4MB/s    in 0.6s    \n",
            "\n",
            "2021-03-17 11:54:30 (84.4 MB/s) - ‘/usr/local/bin/orca’ saved [51607939/51607939]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2\n",
            "  libgail-common libgail18 libgtk2.0-bin libgtk2.0-common\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2\n",
            "  libgail-common libgail18 libgconf-2-4 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common xvfb\n",
            "0 upgraded, 11 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 3,715 kB of archives.\n",
            "After this operation, 17.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdbus-glib-1-2 amd64 0.110-2 [58.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf2-common all 3.2.6-4ubuntu1 [700 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgconf-2-4 amd64 3.2.6-4ubuntu1 [84.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf-service-backend amd64 3.2.6-4ubuntu1 [58.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf-service amd64 3.2.6-4ubuntu1 [2,036 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n",
            "Fetched 3,715 kB in 1s (2,497 kB/s)\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libdbus-glib-1-2_0.110-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.110-2) ...\n",
            "Selecting previously unselected package gconf2-common.\n",
            "Preparing to unpack .../01-gconf2-common_3.2.6-4ubuntu1_all.deb ...\n",
            "Unpacking gconf2-common (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package libgconf-2-4:amd64.\n",
            "Preparing to unpack .../02-libgconf-2-4_3.2.6-4ubuntu1_amd64.deb ...\n",
            "Unpacking libgconf-2-4:amd64 (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package gconf-service-backend.\n",
            "Preparing to unpack .../03-gconf-service-backend_3.2.6-4ubuntu1_amd64.deb ...\n",
            "Unpacking gconf-service-backend (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package gconf-service.\n",
            "Preparing to unpack .../04-gconf-service_3.2.6-4ubuntu1_amd64.deb ...\n",
            "Unpacking gconf-service (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../05-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../06-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../07-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../08-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../09-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../10-xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up gconf2-common (3.2.6-4ubuntu1) ...\n",
            "\n",
            "Creating config file /etc/gconf/2/path with new version\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.110-2) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up libgconf-2-4:amd64 (3.2.6-4ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up gconf-service-backend (3.2.6-4ubuntu1) ...\n",
            "Setting up gconf-service (3.2.6-4ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEFrR-NW8V7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33621894-0ce1-4ab1-90a5-c8b0f29aa10b"
      },
      "source": [
        "!pip install hdbscan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/bb/59a75bc5ac66a9b4f9b8f979e4545af0e98bb1ca4e6ae96b3b956b554223/hdbscan-0.8.27.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 4.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.22)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.15.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl size=2311674 sha256=6457b9a8e7c54acad9f15dc608cbd9fd74bc4427cda7bd874036e096fc09f4b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/63/fb/314ad6c3b270887a3ecb588b8e5aac50b0fad38ff89bb6dff2\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pEfDHsCe9sD"
      },
      "source": [
        "## ICI IL FAUT REDEMARRER L'ENVIRONNEMENT D'EXECUTION (pour employer les transformers (et hdbscan))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z350YABsfDAs"
      },
      "source": [
        "# 1.a\n",
        "# librairies générales (on ne se servira pas forcément de toutes)\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import datetime as dt\n",
        "from ast import literal_eval\n",
        "import json \n",
        "from random import sample\n",
        "import collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EekqaA1_fDbu"
      },
      "source": [
        "# 1.b\n",
        "# librairies générales data science\n",
        "import numpy as np\n",
        "import scipy.stats as ss\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-6QHgo6fDrb"
      },
      "source": [
        "# 1.c\n",
        "# pour affichage dtypes pandas quand plus de 60 colonnes\n",
        "pd.set_option('display.max_rows', 120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "416iyoI5fD6b"
      },
      "source": [
        "# 1.d\n",
        "# la librairie graphique la plus simple d'utilisation\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8CMj9OhyiOz"
      },
      "source": [
        "# 1.f réduction de dimension via UMAP\n",
        "import umap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7maIuBnq8G2"
      },
      "source": [
        "# 1.g clustering de densité (soft) via HDBSCAN\n",
        "import hdbscan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxTcubWWfEfF"
      },
      "source": [
        "# 1.h imports spécifiques à google colab\n",
        "from google.colab import files, drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pebpkNklfEtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18d68f6-3172-4e51-ae09-3e6c239a501b"
      },
      "source": [
        "# 1.i passage obligé pour récupérer un fichier sur le drive\n",
        "# il va falloir choisir le drive (account Google) puis renseigner un mot de passe généré\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaV1U_HduNnl"
      },
      "source": [
        "# 1.j utilisation des transformers HuggingFace dans le cadre de pyTorch\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTw-DHpK8t3Z"
      },
      "source": [
        "# 1.k formatage des données pour entrée dans tokenisateurs HuggingFace\n",
        "from datasets import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIdj8tpP8o-3"
      },
      "source": [
        "# 1.l utilisation des transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForMaskedLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8jzA8QhiB3U"
      },
      "source": [
        "# 1.m utilisation pour le réglage fin du transformer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForLanguageModeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqL2IEWPHyC_"
      },
      "source": [
        "# 1.n utilisation pour la mise en oeuvre du modèle réglé finement (un modèle FlauBERT)\n",
        "from transformers import FlaubertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcePEtD4kmr0"
      },
      "source": [
        "## Structure interne des tokeniseurs et transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jadqr6USKJss"
      },
      "source": [
        "### Choix du modèle BERT\n",
        "##### Pour le français, il y a actuellement deux familles de modèles CamemBERT et FlauBERT dont les niveaux de performance sont très voisins, et supérieurs à ceux des modèle multi-lingues (mBERT) incluant le français\n",
        "##### CamemBERT a demandé plus de ressources à l'entraînement (modèle RoBERTa)\n",
        "##### Un modèle de base est ici suffisant, et uncased vu nos textes de départ, déjà en minuscules pour l'essentiel\n",
        "##### *flaubert-base-uncased*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_7_VO7DH1dR"
      },
      "source": [
        "# 2.a\n",
        "nom_modele = 'flaubert/flaubert_base_uncased' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cz-GkX2k3LR"
      },
      "source": [
        "#### Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8-ynXlJlXpv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "028a14d9e57b48c1965c75481fef7fc4",
            "ca04293b807a4028b4f7ad0ace68d56d",
            "08b8d47c18c244d8850d541af40b37c7",
            "843031c181ce4a84b6a49e3bea1cf0e0",
            "4b64b9c26d5148bf9086a2aa8afdcdbf",
            "e8b4180904c648f480ac301a092cae69",
            "6bd19d6e7b4641deaf793e37078ee186",
            "3819e3f3835b4f09afaa3ae5611218af",
            "acc320f8126c4e58991ecb006f297089",
            "48654baac81c43bcbb5b8d13b578a0fb",
            "10148cfa476d4671b0601a5dc62e61a6",
            "4c570d0dcf3e494480d8cc7543daa1e2",
            "c6dab9da68b248ba8b8f2842df14588d",
            "c131b6e82b2744ceb91a4108de2ea80c",
            "7dd3530cc1954674a4e9a147153dc7f2",
            "d7402b6ec36e43a2aa5803048c712239",
            "ebdab49507984fe088964f4c5f34120d",
            "05508bbb811f46d586db88f4f183ec5a",
            "c959f6b788264b2faa8dbc5f8421cced",
            "37e073730d554a1d979a2a72daff5f24",
            "822e890c48944065985ae2e97c5049da",
            "4d08b1856be34cd38ce8a4fb4c400486",
            "6b42c3494b534d578e0af3513ed5a07d",
            "e4f346e1acb64889b0781046fdbb165c"
          ]
        },
        "outputId": "25f49db8-66cb-446b-9d63-bbb7df183ada"
      },
      "source": [
        "# 2.b\n",
        "# tokeniseur : on essaye le chargement de la version rapide du tokeniseur (si le temps est déjà bon, essayer la version plus lente)\n",
        "tokeniseur = AutoTokenizer.from_pretrained(nom_modele, use_fast=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "028a14d9e57b48c1965c75481fef7fc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1496.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc320f8126c4e58991ecb006f297089",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1562605.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebdab49507984fe088964f4c5f34120d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=917147.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd1iX2z2iCMA"
      },
      "source": [
        "# 2.c\n",
        "# essai sur un texte\n",
        "#texte = \"Le malade a pris de l'hydroxychloroquine, et il aurait effectivement guéri du COVID\"\n",
        "texte = \"Macron a rencontré le professeur Raoult, la discussion a duré 2 heures.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8zoGDUFJYQ9"
      },
      "source": [
        "###### Le tokénisateur est celui de XLM\n",
        "- caractères spéciaux : s (Beginning Of Sentence), /s (Separator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM7pIxoi3qMC"
      },
      "source": [
        "###### tokenize renvoie la liste des tokens (sous forme de texte)\n",
        "- il n'y a pas de séparateurs de début et de fin de bloc\n",
        "- les mots pleins (formes fléchies incluses) sont sous la forme chaîne du mot suivi de /w (fin de mot)\n",
        "- pour les mots hors vocabulaire, il y a N sous-tokens, le dernier étant suivi de /w"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L020BJbiCeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1550195-cbf7-476d-9489-a3b7d0ebfce7"
      },
      "source": [
        "# 2.d\n",
        "texte_tokenise = tokeniseur.tokenize(texte)\n",
        "print(texte_tokenise)\n",
        "print(len(texte_tokenise))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macron</w>', 'a</w>', 'rencontré</w>', 'le</w>', 'professeur</w>', 'raou', 'lt</w>', ',</w>', 'la</w>', 'discussion</w>', 'a</w>', 'duré</w>', '2</w>', 'heures</w>', '.</w>']\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOPLYpJf4n3L"
      },
      "source": [
        "###### encode renvoie la liste des ids de token\n",
        "- y compris les séparateurs de début et de fin de bloc (0 et 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rBqxdRYmhDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b747a8-8bf6-499a-cdd4-8c3fd05bef36"
      },
      "source": [
        "# 2.e\n",
        "texte_encode = tokeniseur.encode(texte)\n",
        "print(texte_encode)\n",
        "print(len(texte_encode))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 3898, 34, 3467, 19, 1841, 36915, 7177, 14, 17, 3120, 34, 10029, 122, 363, 16, 1]\n",
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU2InRjt5Tbb"
      },
      "source": [
        "###### convert_ids_to_tokens renvoie la liste des textes de tokens \n",
        "- y compris les début (s) et fin (/s) de bloc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPa8-xnX4b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41af7401-6d5a-478a-ae58-35d590e01895"
      },
      "source": [
        "# 2.f\n",
        "l_tokens = tokeniseur.convert_ids_to_tokens(texte_encode)\n",
        "print(l_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<s>', 'macron</w>', 'a</w>', 'rencontré</w>', 'le</w>', 'professeur</w>', 'raou', 'lt</w>', ',</w>', 'la</w>', 'discussion</w>', 'a</w>', 'duré</w>', '2</w>', 'heures</w>', '.</w>', '</s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKhw5By851M_"
      },
      "source": [
        "###### convert_tokens_to_string revient au texte initial\n",
        "- avec en plus les débuts (s) et fins (/s) de bloc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmj9W6gW46dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6929801-7ae0-4bf2-9ed1-54d8c3225093"
      },
      "source": [
        "# 2.g\n",
        "texte_reconstitue = tokeniseur.convert_tokens_to_string(l_tokens)\n",
        "print(texte_reconstitue)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s>macron a rencontré le professeur raoult , la discussion a duré 2 heures . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPpDmJvD6Jan"
      },
      "source": [
        "###### encode_plus renvoie un dictionnaire avec 3 éléments :\n",
        "- input_ids : la liste des ids de tokens\n",
        "- token_type_ids : la liste des types de tokens (que des 0 dans le cas standard, les 1 peuvent servir à distinguer une phrase de rôle différent, par exemple question vs réponse)\n",
        "- attention_mask : la liste des masques d'attention (que des 1 si on ne traite qu'un bloc à la fois, on regarde tous les tokens du bloc ; si dans un batch il y a plusieurs blocs, la liste est mise à la longueur la plus grande, et pour les plus courts, on complète avec des 0)\n",
        "- début et fin de bloc sont représentés dans les 3 éléments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JgVCihliDCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96ad5de-4498-4aa7-e4cb-6d039c89121e"
      },
      "source": [
        "# 2.h\n",
        "texte_encode_plus = tokeniseur.encode_plus(texte)\n",
        "print(len(texte_encode_plus))\n",
        "for k, v in texte_encode_plus.items():\n",
        "  print(k, \":\", v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "input_ids : [0, 3898, 34, 3467, 19, 1841, 36915, 7177, 14, 17, 3120, 34, 10029, 122, 363, 16, 1]\n",
            "token_type_ids : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfzkQiex9Z2P"
      },
      "source": [
        "##### utiliser directement le tokéniesur est équivalent à encode_plus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gQqwfKa1WkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a85f45a-2518-4f5e-cdd4-6c7d7481a4d7"
      },
      "source": [
        "# 2.i\n",
        "tokenise = tokeniseur(texte)\n",
        "print(len(tokenise))\n",
        "for k, v in tokenise.items():\n",
        "  print(k, \":\", v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "input_ids : [0, 3898, 34, 3467, 19, 1841, 36915, 7177, 14, 17, 3120, 34, 10029, 122, 363, 16, 1]\n",
            "token_type_ids : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmzNvLxi9sjD"
      },
      "source": [
        "###### On peut aussi garantir un format tenseur (ici pyTorch) en sortie du tokénisateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ridt5-2LNl-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1319ff7-080d-4059-851a-f429122ef0b9"
      },
      "source": [
        "# 2.j\n",
        "texte_tokenise_pt = tokeniseur(texte, return_tensors=\"pt\")\n",
        "for k, v in texte_tokenise_pt.items():\n",
        "  print(k, \":\", v, \"--- shape :\", v.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_ids : tensor([[    0,  3898,    34,  3467,    19,  1841, 36915,  7177,    14,    17,\n",
            "          3120,    34, 10029,   122,   363,    16,     1]]) --- shape : torch.Size([1, 17])\n",
            "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) --- shape : torch.Size([1, 17])\n",
            "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]) --- shape : torch.Size([1, 17])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TecdfsncoXu"
      },
      "source": [
        "###### >>> batch = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "###### >>> print(batch)\n",
        "{'input_ids': tensor([[ 101, 8667,  146,  112,  182,  170, 1423, 5650,  102],\n",
        "                      [ 101, 1262, 1330, 5650,  102,    0,    0,    0,    0],\n",
        "                      [ 101, 1262, 1103, 1304, 1304, 1314, 1141,  102,    0]]),\n",
        " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                           [0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
        " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "                           [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
        "                           [1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evhOagFloypK"
      },
      "source": [
        "###### Vocabulaire du tokénisateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCdDIF3Xo6iL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f472af2f-4932-4b2a-c02e-aeffd9296444"
      },
      "source": [
        "# 2.k\n",
        "# longueur du vocabulaire\n",
        "l_vocab_tokeniseur = list(tokeniseur.get_vocab())\n",
        "print(len(l_vocab_tokeniseur))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNM238z4o6-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65fabcf2-e27a-4951-8c47-9ebb2131606b"
      },
      "source": [
        "# 2.l\n",
        "# quelques éléments du vocabulaire\n",
        "print(l_vocab_tokeniseur[4000:4030])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fleuries</w>', 'œur</w>', 'ṱ', 'sies</w>', 'xiie</w>', 'mit</w>', 'stimule</w>', 'meur', 'intéressants</w>', 'clai', 'dépassent</w>', 'levi', 'vants</w>', 'sommaire</w>', 'oca</w>', 'raill', 'kaf', 'immatricul', 'ҳ</w>', 'chall', 'alexander</w>', 'antérieurs</w>', 'revanche</w>', 'primer</w>', 'oire</w>', '莎', 'oui', 'rcs</w>', 'motivée</w>', '執']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6RGQ29JF2p1"
      },
      "source": [
        "#### Modèle BERT (FlauBERT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGHoFq2o7ga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "bc17843704534910a2b0b7221e5e5c96",
            "b6f8286671a24de59cf2a09ce46aa82a",
            "c8ac3025e5544a47a594371801d02995",
            "dd4ab823aa3e49ca95916f92d128ee93",
            "029342997d104e588cd760c8d0e04ca4",
            "ece74cb65acd4587a98183693bc8a032",
            "68f081be7e1b44a5adf244f754613575",
            "b9f7e080dce74ee2b0d29d06f3b6e9eb"
          ]
        },
        "outputId": "8cd6a0c5-9f6b-485f-af4d-c9ef0898054a"
      },
      "source": [
        "# 3.a\n",
        "# charger le modèle adapté à la prédiction de tokens en contexte\n",
        "# on aura besoin d'examiner les couches en sortie des derniers transformers, pas seulement le dernier\n",
        "modele = AutoModelForMaskedLM.from_pretrained(nom_modele, output_hidden_states = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc17843704534910a2b0b7221e5e5c96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=549587475.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of FlaubertWithLMHeadModel were not initialized from the model checkpoint at flaubert/flaubert_base_uncased and are newly initialized: ['transformer.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCuAkIMgo7vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd4f255-3659-497a-8cd5-a3285487f85b"
      },
      "source": [
        "# 3.b\n",
        "# se mettre en mode exclusivement propagation avancée\n",
        "# en fait, lorsqu'on vient de charger le modèle via from_pretrained, le modèle est déjà en mode \"évaluation\" (par opposition à \"entraînement\")\n",
        "modele.eval()\n",
        "# renvoie la liste des composantes (couches) du modèle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FlaubertWithLMHeadModel(\n",
              "  (transformer): FlaubertModel(\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (embeddings): Embedding(67542, 768, padding_idx=2)\n",
              "    (layer_norm_emb): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (attentions): ModuleList(\n",
              "      (0): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (1): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (2): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (3): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (4): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (5): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (6): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (7): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (8): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (9): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (10): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (11): MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm1): ModuleList(\n",
              "      (0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (4): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (6): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (7): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (8): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (10): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (11): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (ffns): ModuleList(\n",
              "      (0): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (1): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (2): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (3): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (4): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (5): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (6): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (7): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (8): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (9): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (10): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "      (11): TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm2): ModuleList(\n",
              "      (0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (4): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (6): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (7): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (8): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (10): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (11): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pred_layer): XLMPredLayer(\n",
              "    (proj): Linear(in_features=768, out_features=67542, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eZnGX3Lo8EK"
      },
      "source": [
        "# 3.c\n",
        "# mettre en entrée le texte tokenizé, et récupérer la sortie\n",
        "sorties = modele(**texte_tokenise_pt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ8Lnow0wyYR"
      },
      "source": [
        "###### logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "###### hidden_states Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYiI4OPvo8SM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b28045-37e2-4ca6-9184-88e1f3154e6d"
      },
      "source": [
        "# 3.d\n",
        "sorties_logits = sorties['logits']\n",
        "print(type(sorties_logits))\n",
        "print(len(sorties_logits))\n",
        "print(sorties_logits.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "1\n",
            "torch.Size([1, 17, 67542])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22WeFPStI9V8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6e11f1-1f68-4c3e-c484-7376f914e716"
      },
      "source": [
        "# 3.e\n",
        "sorties_transformers = sorties['hidden_states']\n",
        "print(type(sorties_transformers))\n",
        "print(len(sorties_transformers))\n",
        "for l in range(len(sorties_transformers)):\n",
        "  print(type(sorties_transformers[l]))\n",
        "  print(l, sorties_transformers[l].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "13\n",
            "<class 'torch.Tensor'>\n",
            "0 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "1 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "2 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "3 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "4 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "5 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "6 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "7 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "8 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "9 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "10 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "11 torch.Size([1, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "12 torch.Size([1, 17, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFI9LXc7I-LJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6254762-5706-46ec-b351-1336e7dd7bde"
      },
      "source": [
        "# 3.f\n",
        "# récupérer le 1er élément du 1er tenseur, et le tout dernier\n",
        "print(sorties_transformers[0][0, 0, 0])\n",
        "print(sorties_transformers[12][0, 16, 767])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-0.2951, grad_fn=<SelectBackward>)\n",
            "tensor(0.6149, grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MTacCK6wu8l"
      },
      "source": [
        "#### Sélectionner / reformater sorties des transformers pour une exploitation facilitée des couches\n",
        "###### Notamment pour extraire un embedding représentatif de la transformation des tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sETkAMD4vhUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2452bd29-a05d-4154-c3fa-9b083006746a"
      },
      "source": [
        "# 3.g\n",
        "# concaténer toutes les couches\n",
        "embeddings_tokens = torch.stack(sorties_transformers, dim=0)\n",
        "print(embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13, 1, 17, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjAI7Nu0B2Lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5d058e-da89-4654-b466-0d09e8c9a995"
      },
      "source": [
        "# 3.h\n",
        "# éliminer la dimension batch (n° 1 maintenant)\n",
        "embeddings_tokens = torch.squeeze(embeddings_tokens, dim=1)\n",
        "print(embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13, 17, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs7nVK_xB2yK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f689ce6-14d8-4205-b10f-a0c894c5de04"
      },
      "source": [
        "# 3.i\n",
        "# permuter dimensions des couches et des tokens\n",
        "embeddings_tokens = embeddings_tokens.permute(1, 0, 2)\n",
        "print(embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([17, 13, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZdl5thR_j8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98757bf8-81c1-4c14-8436-93330a551653"
      },
      "source": [
        "# 3.j\n",
        "# on peut transformer le tout en numpy array\n",
        "mx_embeddings_tokens = embeddings_tokens.cpu().detach().numpy()\n",
        "print(mx_embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17, 13, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQSmnMVKF7jh"
      },
      "source": [
        "###### Obtention des vecteurs de tokens, puis de phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDPzBsVDvhrW"
      },
      "source": [
        "# 3.k\n",
        "# une stratégie classique est de moyenner les N dernières couches\n",
        "NB_DERNIERES_COUCHES = 4\n",
        "ix_dernieres_couches = 13 - NB_DERNIERES_COUCHES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cql5ejaOvh9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb52d219-ef15-4b80-d227-98f73789f5be"
      },
      "source": [
        "# 3.l\n",
        "# sélection des dernières couches\n",
        "mx_sel_N_dernieres_couches = mx_embeddings_tokens[:, ix_dernieres_couches:, :]\n",
        "print(mx_sel_N_dernieres_couches.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17, 4, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZzNQ3Ozysok",
        "outputId": "b12350df-14ee-4ad4-88dc-6c257cb8cafe"
      },
      "source": [
        "# 3.m\n",
        "# pour chaque token (1ère dimension) il faut sommer sur les N couches (2ème dimension), en gardant les embeddings (dernière dimension)\n",
        "# les tokens sont alors en ligne, et les embeddings toujours en colonne\n",
        "mx_somme_N_dernieres_couches = np.sum(mx_sel_N_dernieres_couches, axis=1)\n",
        "print(mx_somme_N_dernieres_couches.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaroYnWCytDr",
        "outputId": "ba7d8599-fc98-4fb8-ccff-66c9382bbe8b"
      },
      "source": [
        "# 3.n\n",
        "# pour un embedding de sentence, on réduit encore en sommant sur l'axe 0 (celui des tokens, qu'on élimine)\n",
        "mx_somme_sur_bloc = np.sum(mx_somme_N_dernieres_couches, axis=0)\n",
        "print(mx_somme_sur_bloc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZxOdv_5BXIC"
      },
      "source": [
        "#### Traitement en batch de plusieurs textes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuTP6bnNBhJa"
      },
      "source": [
        "# 3.o\n",
        "# ici deux textes, de longueurs différentes\n",
        "l_textes = [\"Macron a rencontré le professeur Raoult, la discussion a duré 2 heures.\", \"Vraiment ?\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU3l80jmGIZv"
      },
      "source": [
        "###### Comme on a des textes de différentes longueurs, il faut demander de compléter la suite des textes les moins courts (padding=True). Il est aussi plus prudent de demander la troncation des textes les plus longs pour qu'ils puissent entrer dans le transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS4SkKGEBhfJ",
        "outputId": "baea667b-707b-41ce-9468-a18a6f5c232f"
      },
      "source": [
        "# 3.p\n",
        "# tokénisation de la liste de textes\n",
        "l_textes_tokenises_pt = tokeniseur(l_textes, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "for k, v in l_textes_tokenises_pt.items():\n",
        "  print(k, \":\", v, \"--- shape :\", v.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_ids : tensor([[    0,  3898,    34,  3467,    19,  1841, 36915,  7177,    14,    17,\n",
            "          3120,    34, 10029,   122,   363,    16,     1],\n",
            "        [    0,   367,    88,     1,     2,     2,     2,     2,     2,     2,\n",
            "             2,     2,     2,     2,     2,     2,     2]]) --- shape : torch.Size([2, 17])\n",
            "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) --- shape : torch.Size([2, 17])\n",
            "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) --- shape : torch.Size([2, 17])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gKXBYNmLoKt",
        "outputId": "cef95276-33ba-44d4-e37e-c2bece4299e5"
      },
      "source": [
        "# 3.q\n",
        "# on peut pour chaque texte récupérer le nb de tokens avant padding\n",
        "l_len_textes = []\n",
        "for no_texte in range(len(l_textes)):\n",
        "  masque_attention = l_textes_tokenises_pt['attention_mask'][no_texte]\n",
        "  nb_tokens = masque_attention.shape[0]\n",
        "  len_texte = 0\n",
        "  for m in range(nb_tokens):\n",
        "    if masque_attention[m] == 1: len_texte += 1\n",
        "    else: break\n",
        "  l_len_textes.append(len_texte)\n",
        "print(l_len_textes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR_D0z5JBh2J"
      },
      "source": [
        "# 3.r\n",
        "# mettre en entrée les textes tokenizés, et récupérer la sortie\n",
        "sorties = modele(**l_textes_tokenises_pt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePEPhUgoGgfM"
      },
      "source": [
        "##### 13 couches cachées de format [nb de textes du batch, nb de tokens pour chaque texte, nb de dimensions d'embedding]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK2o23THBiHZ",
        "outputId": "3cb793b4-643d-40e4-fe37-f0b979bfeb9a"
      },
      "source": [
        "# 3.s\n",
        "# examen des couches cachées\n",
        "sorties_transformers = sorties['hidden_states']\n",
        "print(type(sorties_transformers))\n",
        "print(len(sorties_transformers))\n",
        "for l in range(len(sorties_transformers)):\n",
        "  print(type(sorties_transformers[l]))\n",
        "  print(l, sorties_transformers[l].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "13\n",
            "<class 'torch.Tensor'>\n",
            "0 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "1 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "2 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "3 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "4 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "5 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "6 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "7 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "8 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "9 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "10 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "11 torch.Size([2, 17, 768])\n",
            "<class 'torch.Tensor'>\n",
            "12 torch.Size([2, 17, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGdK8VbBiWp",
        "outputId": "94993aea-c788-4414-c784-9d2e0e60d674"
      },
      "source": [
        "# 3.t\n",
        "# concaténer toutes les couches\n",
        "embeddings_tokens = torch.stack(sorties_transformers, dim=0)\n",
        "print(embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13, 2, 17, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhgrO1C-DXJV",
        "outputId": "30006a7d-efc7-44ff-9990-1bc5fa6f0801"
      },
      "source": [
        "# 3.u\n",
        "# permuter les dimensions de façon à avoir l'ordre batch, tokens, couches et embeddings\n",
        "embeddings_tokens = embeddings_tokens.permute(1, 2, 0, 3)\n",
        "print(embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 17, 13, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cbZ5lISD2jH",
        "outputId": "11100b45-7efa-408b-b09a-acb5f8fd5aaf"
      },
      "source": [
        "# 3.v\n",
        "# on peut transformer le tout en numpy array\n",
        "mx_embeddings_tokens = embeddings_tokens.cpu().detach().numpy()\n",
        "print(mx_embeddings_tokens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 17, 13, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkX99mrqLWUn"
      },
      "source": [
        "# 3.w\n",
        "# une stratégie classique est de moyenner les N dernières couches\n",
        "NB_DERNIERES_COUCHES = 4\n",
        "ix_dernieres_couches = 13 - NB_DERNIERES_COUCHES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XhAio6xBioZ",
        "outputId": "c6020910-ef39-45dc-f88d-586cc04a06b4"
      },
      "source": [
        "# 3.x\n",
        "# boucler texte par texte (sur la dimension batch)\n",
        "nb_textes = mx_embeddings_tokens.shape[0]\n",
        "for no_texte in range(nb_textes):\n",
        "  print(no_texte)\n",
        "\n",
        "  # extraire l'embedding du texte\n",
        "  mx_texte_embeddings_tokens = mx_embeddings_tokens[no_texte]\n",
        "\n",
        "  # sélection des dernières couches\n",
        "  mx_sel_N_dernieres_couches = mx_texte_embeddings_tokens[:, ix_dernieres_couches:, :]\n",
        "  print(mx_sel_N_dernieres_couches.shape)\n",
        "\n",
        "  # pour chaque token (1ère dimension) il faut sommer sur les N couches (2ème dimension), en gardant les embeddings (dernière dimension)\n",
        "  # les tokens sont alors en ligne, et les embeddings toujours en colonne\n",
        "  mx_somme_N_dernieres_couches = np.sum(mx_sel_N_dernieres_couches, axis=1)\n",
        "  print(mx_somme_N_dernieres_couches.shape)\n",
        "\n",
        "  # vérification de l'effet du padding (le second texte fait 4 de long)\n",
        "  for i in [0, 1, 2, 3, 4, 15, 16]:\n",
        "    print(i, mx_somme_N_dernieres_couches[i][0], mx_somme_N_dernieres_couches[i][767])\n",
        "\n",
        "  # pour un embedding de sentence, on réduit encore en sommant sur l'axe 0 (celui des tokens, qu'on élimine)\n",
        "  mx_somme_sur_bloc = np.sum(mx_somme_N_dernieres_couches, axis=0)\n",
        "  print(mx_somme_sur_bloc.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(17, 4, 768)\n",
            "(17, 768)\n",
            "0.22845879 2.6680057\n",
            "-0.73210144 2.6488466\n",
            "-1.3033249 1.7048044\n",
            "-0.7059021 -1.8785855\n",
            "0.81676507 0.32797867\n",
            "-0.14851315 0.57719284\n",
            "(768,)\n",
            "1\n",
            "(17, 4, 768)\n",
            "(17, 768)\n",
            "2.2612886 3.9173677\n",
            "1.8151124 4.400249\n",
            "2.1075423 4.393114\n",
            "0.0 0.0\n",
            "0.0 0.0\n",
            "0.0 0.0\n",
            "(768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYDObtFPBj7x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kW2qlYs5vGl"
      },
      "source": [
        "## Lecture du fichier de 1300 vidéos prétraitées\n",
        "##### Prétraitées : on a effectué au préalable l'analyse nlp de Spacy sur les sous_titres et renseigné :\n",
        "###### 'textes_sous_titres_avec_bigrammes', texte ne contenant que les lemmes pleins, éventuellement regroupés en bigrammes pertinents\n",
        "###### en plus de ce qui avait été précédemment utilisé\n",
        "###### 'langue' langue de la vidéo tel que détecté par spacy (on garde 'fr')\n",
        "###### 'tkn_sous_titres' listes de token avec un tuple par token\n",
        "###### 'ent_sous_titres' liste d'entités nommées avec un tuple par entité nommée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6w7l6axgCN7"
      },
      "source": [
        "# 4.a sous-répertoire éventuellement à adapter\n",
        "chemin_nom_dataframe = \"/content/drive/My Drive/Datasets NLP/COVID 19/videos_covid_nlp_2.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_rz0paNgCdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1604f187-5185-4ed6-a914-340e4ddd497b"
      },
      "source": [
        "# 4.b\n",
        "df_videos = pd.read_csv(chemin_nom_dataframe, sep=',', encoding='utf-8')\n",
        "nb_videos = len(df_videos)\n",
        "print(nb_videos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj4bgOlsj_R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d944e7f1-0ca8-4704-fb0b-280a3affafed"
      },
      "source": [
        "# 4.c\n",
        "df_videos.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "video_id                              object\n",
              "channel_id                            object\n",
              "titre                                 object\n",
              "description                           object\n",
              "date_publication                      object\n",
              "durée                                 object\n",
              "catégorie_YT                         float64\n",
              "tags                                  object\n",
              "nb_vues                              float64\n",
              "nom_chaîne                            object\n",
              "sous_titres                           object\n",
              "nb_mots                              float64\n",
              "mode_création                         object\n",
              "nb_vues_chaîne                         int64\n",
              "catégorie_SP                          object\n",
              "langue_sous_titres                    object\n",
              "tkn_sous_titres                       object\n",
              "ent_sous_titres                       object\n",
              "l_textes_l_tokens                     object\n",
              "textes_sous_titres_avec_bigrammes     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBbWY3twsuAg"
      },
      "source": [
        "# 4.d\n",
        "nb_docs = nb_videos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m4mYnAEYKpE"
      },
      "source": [
        "###### Auparavant, normaliser la colonnes sous-titres (enlever les [MUSIQUE] et autres informations sonores)\n",
        "###### Il faut aussi passer les éventuelles majuscules en minuscules, car les sous-titres sont à la base en minuscule, et on va utiliser un modèle BERT en minuscules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjTLYrO5erIj"
      },
      "source": [
        "# 4.e\n",
        "# mais avant normaliser les sous-titres\n",
        "# éliminer [Musique] et chaînes analogues...\n",
        "FOND_SONORE = re.compile('\\[\\w+\\]')\n",
        "def normalise_sous_titre(text):\n",
        "    text_normalise = re.sub(FOND_SONORE, \"\", text)\n",
        "    return text_normalise\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQH8ChmaZ-58"
      },
      "source": [
        "# 4.f\n",
        "df_videos['texte_base'] = df_videos['sous_titres'].apply(lambda x: normalise_sous_titre(x).lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDSu5C6O2am6"
      },
      "source": [
        "## Réglage fin du modèle Flaubert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6xuGtoLCz1e"
      },
      "source": [
        "#### Pour cette partie, il faut passer le notebook en mode GPU\n",
        "###### Pour ce, aller dans Modifier | Paramètres du notebook, choisir GPU comme Accélérateur matériel "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axP1pz5i3Fhb"
      },
      "source": [
        "##### En préalable, créer un dataset avec un jeu d'entraînement et un jeu de test\n",
        "###### On utilise la colonne sous-titres de texte d'origine, car les embeddings BERT (et les autres d'ailleurs) prennent en compte tous les mots (stop-words compris) et sous leurs formes fléchies (les flexions étant prises en compte au niveau des subtokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GczdnCCM30fR"
      },
      "source": [
        "##### Pour le réglage-fin, on est uniquement intéressé par la colonne de texte qui va être utilisé pour\n",
        "##### On crée un dataset HuggingFace à partir du dataframe pandas\n",
        "##### Et dessus, on fait une séparation entre textes d'entraînement et textes de validation, par une méthode inspirée de scikit-learn "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFiCuBzCZ_hp"
      },
      "source": [
        "# 5.a\n",
        "df_texte = df_videos[['texte_base']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp2ocnlwH0qx"
      },
      "source": [
        "# 5.b\n",
        "ds_texte = Dataset.from_pandas(df_texte)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYZHM0wLH0Nc"
      },
      "source": [
        "# 5.c\n",
        "# l'objet créé est un dictionnaire de datasets, avec un dataset 'train' et un dataset 'test'\n",
        "# on a pris 80 % des données pour l'entraînement, 20 % pour le test\n",
        "# lorsque le nombre de textes est grand, on peut en réserver plus pour l'entraînement\n",
        "ds_texte = ds_texte.train_test_split(test_size=0.2)\n",
        "ds_train = ds_texte['train']\n",
        "ds_test = ds_texte['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzpl4VYiGAMd"
      },
      "source": [
        "##### Vérification, avec fonction directement recopiée d'un notebook Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27xb995iH1Na"
      },
      "source": [
        "# 5.d\n",
        "from datasets import ClassLabel\n",
        "import random\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9dtUTpbGJko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "71516c87-18c9-4300-d9d7-1b6ba0deae6d"
      },
      "source": [
        "# 5.e\n",
        "show_random_elements(ds_train, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texte_base</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Une seule souche avec de nombreux variants serait en circulation actuellement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>la vaccination va enfin accélerer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A quand le déconfinement ??</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7AfZUznH086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "052727af-2ea6-4dcc-af2d-1fcb7c065035"
      },
      "source": [
        "# 5.f\n",
        "show_random_elements(ds_test, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texte_base</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La séquence du génome est publiée dès le 5 janvier, moins d'une semaine après identification du virus.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWTpBRz6xPVq"
      },
      "source": [
        "#### Tokenisation\n",
        "###### On utilise le tokénisateur d'origine via l'objet AutoTokenizer qui le retrouve d'après le nom du modèle qui a été fourni (model checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XW4gYw1H1th",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "b8829aa9d5aa4daaaa443bdae59ee6e7",
            "45c2372936504c72b688bdce21fac490",
            "3a67931399444cc2994feceb78e65230",
            "b3c2db76eb054b36acf88dba83606d20",
            "34d8c51980154aba89a9ee39546b9555",
            "77429a46194f4e9e842e7882d0bcfc49",
            "52fcb9d0125940f7b38b76856aabf1a9",
            "f0348447da944e289abdbf9e06d9d1b5",
            "2dbd442a7f364bea97385bcf828610a7",
            "50b847f64d8e4088a11c41cf00c576e2",
            "d91e63f7ed98475ca9fa500eafc9c6f6",
            "d4a14f9629c64bbc838f050b6e3665a6",
            "0b5b42595fa64d0ebdb0876fec70c78d",
            "285bc3c944a947c782d530dff99c5809",
            "8764e353b6ad49cabcfccf1959108b22",
            "04ba12c14ca64d5fbdf5a28ca3fd273b",
            "9c4c2bc619524cb184f96410877f889a",
            "fae150f505384f9a983617284142915f",
            "9d0bc29403ae4c6d815317a20c14ba16",
            "fd2732adec5a4ae3bf62e65614e37e72",
            "ecd55764c2d341fc8c33341262926bb1",
            "5e9e828f68bd4aea81608ed8c5a40af0",
            "b13983e5aef84feba0a1a57885c78b69",
            "02337d4f2b7e4945b4922fdd40bdb95c"
          ]
        },
        "outputId": "30afab54-f663-4bea-d3dc-9a83e39548f3"
      },
      "source": [
        "# 5.g\n",
        "# tokeniseur : on essaye le chargement de la version rapide du tokeniseur (si le temps est déjà bon, essayer la version plus lente)\n",
        "tokeniseur = AutoTokenizer.from_pretrained(nom_modele, use_fast=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8829aa9d5aa4daaaa443bdae59ee6e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1496.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dbd442a7f364bea97385bcf828610a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1562605.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4c2bc619524cb184f96410877f889a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=917147.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RugePNNg7-b2"
      },
      "source": [
        "# 5.h\n",
        "# fonction à employer sur le dataset pour utiliser le tokeniseur\n",
        "def tokenise(a_traiter):\n",
        "    return tokeniseur(a_traiter[\"texte_base\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVV45f3giSr"
      },
      "source": [
        "###### La fonction map applique une fonction de transformation au dataset, par exemple une tokenisation\n",
        "###### Les principaux arguments sont :\n",
        "- la fonction de transformation\n",
        "- batched : si on procède par batches de documents (1000 par 1000 par défaut, pour argument batch_size)\n",
        "- num proc : mis en oeuvre si on a plusieurs processeurs, par défaut sur 1 processeur\n",
        "- input_columns : liste des colonnes à traiter, par défaut toutes\n",
        "- remove_columns : liste des colonnes du dataset à retirer car ne seront plus utiles par la suite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQUtSwbM7-Hn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "2696d9487a5e492bbb637f7d563a1ae2",
            "f93492a33a61450f8208e50be98c1355",
            "fe4d427b3bf146cd87f3b7d15fb58eac",
            "b3fe3ea760774944b93d00154101042a",
            "7af0a3e2d769436f98e41182212b893c",
            "9e229b20f9b44925a3fe35edbcec212f",
            "1653d70e4a6f497cbb90ec4ce79fce51",
            "dec0abcb82394b339187e907a63d6dbf",
            "679738b08cd646f2be45916ec228831a",
            "aee63e358c1b46b0ba1bdffd43169e96",
            "0ac2eaa29f714ac18800117139004f04",
            "975c68c690c04f61b68509e436cfa879",
            "a03ac03d8cb84c1e976afef7c870eadf",
            "01e12301790e438986c0a4208887ce56",
            "580bb01aab2b47a087f513437853ef88",
            "9f89bf83d12f4acd8eed3e10e66284e4"
          ]
        },
        "outputId": "4668efe3-67ff-4bea-f527-87a05f676dd4"
      },
      "source": [
        "# 5.i\n",
        "# tokenisation sur l'unique colonne texte_base, qu'on retire par la suite\n",
        "ds_texte_tokenise = ds_texte.map(tokenise, batched=True, num_proc=4, remove_columns=[\"texte_base\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2696d9487a5e492bbb637f7d563a1ae2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "679738b08cd646f2be45916ec228831a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkZQ8T0p8WXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6ca890-4369-4891-834d-5548e0b30a32"
      },
      "source": [
        "# 5.j\n",
        "# Examen du résultat\n",
        "ds_texte_tokenise[\"train\"][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [0, 17, 12327, 173, 375, 49387, 544, 311, 1],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv69CMSRumh9",
        "outputId": "ba69271f-e47f-4599-ed97-8a5f4b5ce99a"
      },
      "source": [
        "# 5.k\n",
        "print(\"train\")\n",
        "len_train = len(ds_texte_tokenise[\"train\"])\n",
        "for k in range(len_train):\n",
        "  print(ds_texte_tokenise[\"train\"][k])\n",
        "print(\"test\")\n",
        "len_test = len(ds_texte_tokenise[\"test\"])\n",
        "for k in range(len_test):\n",
        "  print(ds_texte_tokenise[\"test\"][k])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 21, 6213, 57, 68, 11842, 30, 17418, 30, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 17, 12327, 173, 375, 49387, 544, 311, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 19, 1841, 36915, 7177, 34, 1359, 26, 2935, 6367, 127, 19, 480, 823, 3309, 830, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 434, 14, 35, 53, 777, 42, 15, 2717, 2005, 38, 19, 502, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 34, 137, 19, 279, 31391, 88, 88, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 347, 488, 14, 21, 6213, 15, 13904, 49, 57, 24217, 24903, 24, 133, 16, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 29, 469, 15014, 46, 15, 405, 6385, 1269, 335, 24, 2243, 913, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 19, 526, 488, 6371, 14, 22, 10042, 15, 480, 823, 3309, 830, 27, 12079, 29145, 39, 22, 8475, 14, 36, 281, 23, 500, 15, 590, 5584, 31, 3696, 17, 22570, 23, 255, 15, 996, 15230, 13938, 286, 18, 1956, 22, 6454, 16125, 41, 4746, 23, 20416, 19216, 3831, 14, 41140, 18, 17736, 15, 1172, 14, 179, 23, 1233, 7467, 33611, 106, 32, 23, 5312, 18, 3752, 126, 7132, 14, 1736, 28, 10206, 23, 1172, 14, 247, 24, 525, 15, 8025, 14, 1178, 40, 16, 31, 17623, 17, 343, 15, 521, 7758, 15, 30753, 18, 4411, 21, 2231, 25, 1077, 15, 115, 6530, 14, 15, 405, 120, 8566, 23, 500, 15, 31391, 14, 17, 3356, 15, 115, 2921, 18, 22, 6568, 23, 3297, 7191, 18, 11667, 3534, 2814, 16, 76, 1728, 64, 23, 1902, 1282, 14, 1572, 18, 8532, 18, 403, 9710, 23, 14717, 18, 23, 10395, 38, 22, 826, 990, 18, 38, 22, 999, 14, 17, 299, 18, 21, 357, 5212, 23, 2348, 16, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "test\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 17, 5647, 28, 24690, 27, 4016, 298, 19, 192, 518, 14, 121, 25, 29, 466, 102, 4054, 28, 3941, 16, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 17, 420, 15, 17, 2856, 1057, 12402, 47582, 7506, 27, 19, 30, 12336, 25, 23804, 30, 15, 17, 1064, 127, 17, 29145, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn2Q0jqrs1NJ"
      },
      "source": [
        "#### découpage des documents en blocs de taille limitée (\"phrases\") en entrée du transformeur. En général la taille pour BERT est de 512 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5E8ACKD7-uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e85cb8-b616-4167-9130-a6293efb7619"
      },
      "source": [
        "# 5.l\n",
        "# voir taille maximum (nb de modèles) acceptée par \n",
        "print(tokeniseur.model_max_length)\n",
        "# \n",
        "taille_bloc = 128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxNNVbxzC0bA"
      },
      "source": [
        "##### Fonction directement copiée / adaptée du notebook HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-wVJ7EA7_T1"
      },
      "source": [
        "# 5.m\n",
        "def groupe_decoupe_textes(a_traiter):\n",
        "    \n",
        "    # Concaténation de tous les textes du batch à traiter\n",
        "    # on \"somme\" les listes de tokens\n",
        "    # k: 'attention_mask', 'input_ids', 'token_type_ids'\n",
        "    textes_concatenes = {k: sum(a_traiter[k], []) for k in a_traiter.keys()}\n",
        "    \n",
        "    # et on prend la longueur de l'ensemble\n",
        "    long_concatenes = len(textes_concatenes[list(a_traiter.keys())[0]])\n",
        "    # en fait, on découpe l'ensemble en blocs, puis pour faire simple, on ne garde pas le dernier bloc, incomplet\n",
        "    # taille_bloc en contexte global\n",
        "    long_concatenes = (long_concatenes // taille_bloc) * taille_bloc\n",
        "    # faire le découpage par bloc\n",
        "    resultat = {\n",
        "        k: [t[i : i + taille_bloc] for i in range(0, long_concatenes, taille_bloc)]\n",
        "        for k, t in textes_concatenes.items()\n",
        "    }\n",
        "    resultat[\"labels\"] = resultat[\"input_ids\"].copy()\n",
        "    return resultat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrW5oqhECpQt"
      },
      "source": [
        "# 5.n\n",
        "# transformation du dataset avec groupement / découpage en bloc des textes\n",
        "ds_modele_langue = ds_texte_tokenise.map(\n",
        "    groupe_decoupe_textes,\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        "    num_proc=4,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdEBKSXg7_rs"
      },
      "source": [
        "# 5.o\n",
        "# vérification :\n",
        "tokeniseur.decode(ds_modele_langue[\"train\"][0][\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enzY1Dt_jmFV"
      },
      "source": [
        "# 5.p\n",
        "for k, x in ds_modele_langue.items(): print(k, len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAT83CPNQ56J"
      },
      "source": [
        "### Importation du modèle de langue pré-entrainé\n",
        "##### Ce modèle correspond au choix du nom du modèle donné plus haut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-sdmsUt8APM"
      },
      "source": [
        "# 5.q\n",
        "modele = AutoModelForMaskedLM.from_pretrained(nom_modele)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aR07h27TN2R"
      },
      "source": [
        "##### La fonction data_collator prends les exemplaires et les transforme en tensor, tout en faisant du masquage aléatoire. L'entraînement consiste à prédire l'élément masqué. En faisant le masquage aléatoire à ce niveau, et non en pré-processing, on s'assure de l'aléatoirité du masquage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lDQt3lZYML0"
      },
      "source": [
        "###### 15 % des tokens sont masqués"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8lo1daoXt17"
      },
      "source": [
        "# 5.r\n",
        "collateur = DataCollatorForLanguageModeling(tokenizer=tokeniseur, mlm_probability=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GM4JImrYdFV"
      },
      "source": [
        "##### Arguments d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHfaS5AlRyiv"
      },
      "source": [
        "# 5.s\n",
        "args_apprentissage = TrainingArguments(\n",
        "    \"test-mlm\", # et non clm ??\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96bjhFTRyy_"
      },
      "source": [
        "# 5.t\n",
        "trainer = Trainer(\n",
        "    model=modele,\n",
        "    args=args_apprentissage,\n",
        "    train_dataset=ds_modele_langue[\"train\"],\n",
        "    eval_dataset=ds_modele_langue[\"test\"],\n",
        "    data_collator=collateur,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuwciOwtEZXz"
      },
      "source": [
        "#### Apprentissage proprement dit, cellule à grand temps d'exécution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KgQj1-sRzWf"
      },
      "source": [
        "# 5.u\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX49U2x2Rz5P"
      },
      "source": [
        "# 5.v\n",
        "resultats_eval = trainer.evaluate()\n",
        "print(f\"Perplexité: {math.exp(resultats_eval['eval_loss']):.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHp_a9SdxeXZ"
      },
      "source": [
        "### Sauvegarde du modèle pour réutilisation ultérieure\n",
        "##### Dans un répertoire particulier, un répertoire par modèle (ici on suppose qu'un seul modèle suffira, pas besoin de sous-répertoires)\n",
        "###### 2 fichiers :\n",
        "- pytorch_model.bin : 524 Mo\n",
        "- config.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50itPkxSR0Kn"
      },
      "source": [
        "# 5.w\n",
        "modele.save_pretrained(\"/content/drive/My Drive/Datasets NLP/COVID 19\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC0QNOXC6XmQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAy0u_uwOq4m"
      },
      "source": [
        "## Création d'un modèle de topics à partir des embeddings BERT\n",
        "###### En s'inspirant de ce qui a été fait dans BERTopic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDwBrMDGO3zm"
      },
      "source": [
        "#### Chaque document est découpé en blocs de taille ingérable par le transformer BERT\n",
        "- le maximum est de 512 tokens tout compris\n",
        "- en l'absence de découpage par phrase (pour nos sous-titres de vidéos YouTube, sauf pour une minorité d'entre elles), on va découper les documents en bloc de taille égale\n",
        "- ce découpage peut avoir lieu avant ou après tokénisation BERT, on va le faire avant. Pour éliminer tous risques on va prendre des blocs de 64 tokens.\n",
        "- point très important : pour le texte en entrée du tokéniseur, on ne peut pas y introduire des bigrammes/trigrammes de la forme XXXX_YYYY. Par ailleurs, BERT est plus précis si on fournit le texte complet (formes fléchies, présence des stop-words.) On utilise donc le texte d'origine. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnmmKK6dO4Ic"
      },
      "source": [
        "#### On prend chaque bloc de texte et on calcule son embedding (dans un espace de 768 dimension)\n",
        "- Chaque bloc de texte est rattaché à son document d'origine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaOBkKr5O4j8"
      },
      "source": [
        "#### On performe un regroupement (clustering) de ces blocs de texte\n",
        "- les regroupements correspondent à 1 et 1 seul topic, chaque bloc de texte est dans 1 et 1 seul topic\n",
        "- mais un document appartiendra dans des proportions diverses à plusieurs topics, si des blocs sont dans des topics différents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ow9wNsVYQ-P"
      },
      "source": [
        "#### On crée la correspondance termes topics en utilisant les blocs de textes associés aux topic\n",
        "- pour chaque topic on concatène tous les blocs de texte qui y sont rattachés, et on applique un calcul tf-idf sur chaque terme de ces textes de topic \n",
        "- il vaut mieux utiliser concaténer les textes lemmatisés et avec bigrammes/trigrammes pour une matrice termes topics utilisable \n",
        "- pour ce il faut établir la correspondance entre blocs de texte complets et blocs de texte retravaillé ; elle sera ici sommaire, mais ce n'est pas trop grave vu comme le découpage a été fait en blocs de tailles égales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVkzQN-VYyHG"
      },
      "source": [
        "#### Au final, on a les deux matrices documents X topics et topics X termes, qu'on peut utiliser comme d'autres analyses de topics sur des modèles plus classiques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nfv1h-mHZVD"
      },
      "source": [
        "###### ------ Fin de la présentation générale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRDpwyWpgor-"
      },
      "source": [
        "#### Pour cette partie, il faut passer le notebook en mode GPU\n",
        "###### Pour ce, aller dans Modifier | Paramètres du notebook, choisir GPU comme Accélérateur matériel "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taER8VOGHWMt"
      },
      "source": [
        "### Chargement du modèle réglé finement pour étude des topics des documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OluAWe2Z_Ju",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "e457c451a24d42bd8172d682b262a833",
            "8dbbd15ed92f4e528baa4cdb8893f88e",
            "ab2e57f2e9fc424fae860b10a2986b1c",
            "2214b698a79f4cbebb85098598b7cee3",
            "928d0f10704c408fa70afc322e719dd4",
            "bb9a5825db964e04937184bd06432e47",
            "061eae2742be4eae94c4bf2df3a7f6ea",
            "36a1e82badce4b9c8357d0da958a6424",
            "385719e2186145c99b68754eec71ae7c",
            "a2683be894544a06a1e9014318c6dd08",
            "81739e24978d45528d817b7b64fb3963",
            "3260b22faa3f4b0f9e04f2f746434862",
            "cd9f1b9fcf0e497999fdc645005db057",
            "dc216a4166b44b8b8d70fb77d1533a88",
            "4758fc0e80f14e3b81bf52fa7309cabf",
            "faa82179f78c431da830d296414aae69",
            "f51fb6a95aab4641bea758265431c899",
            "e5f2981d4953431fbf1a4fe1419d3d4d",
            "f530c6b97c244d04bed199c514381e2e",
            "91eafd446b9d40808a9b5482c01c495d",
            "cf8115eb2e7e49e887bf8421d9906444",
            "ebde16e32f3a490f9c25b0066522a415",
            "85f8b06fb08b488e9846a63536021217",
            "9185edad3bec473f9544e9d78b495de2",
            "0d373def94fd44e4bb5139d0ab242410",
            "55e3d0ff02df49fcb82a416fc1ba234b",
            "9f9a01ce3ca84ff19e0c245ecb3909a5",
            "263ba2e2a4c0479886b1c14b309a5665",
            "e3baaedf56c9450abedf0c2e0b3a2a77",
            "071482cab354414a936f541378054a53",
            "4feb1a89d6fd43b9a694de015a0eecc3",
            "13fd87a51f8c44d9a8af82b2d870e71d"
          ]
        },
        "outputId": "04a4fd90-d8ac-4fc2-ec98-f46987965f29"
      },
      "source": [
        "# 6.a\n",
        "# le tokeniseur est le tokéniseur standard\n",
        "tokeniseur = AutoTokenizer.from_pretrained('flaubert/flaubert_base_uncased', use_fast=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e457c451a24d42bd8172d682b262a833",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1496.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "385719e2186145c99b68754eec71ae7c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1562605.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f51fb6a95aab4641bea758265431c899",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=917147.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d373def94fd44e4bb5139d0ab242410",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=27.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNtm3tFcR5GF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1659af-39db-41bd-c550-7a0d6a0a6d69"
      },
      "source": [
        "# 6.b\n",
        "# mais le modèle est celui qui a été (ré)entraîné, réglé finement\n",
        "modele = FlaubertModel.from_pretrained(\"/content/drive/My Drive/Datasets NLP/COVID 19\", output_hidden_states = True)\n",
        "# se mettre en mode exclusivement propagation avancée\n",
        "# en fait, lorsqu'on vient de charger le modèle via from_pretrained, le modèle est déjà en mode \"évaluation\" (par opposition à \"entraînement\")\n",
        "modele.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FlaubertModel(\n",
              "  (position_embeddings): Embedding(512, 768)\n",
              "  (embeddings): Embedding(67542, 768, padding_idx=2)\n",
              "  (layer_norm_emb): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (attentions): ModuleList(\n",
              "    (0): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (1): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (2): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (3): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (4): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (5): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (6): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (7): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (8): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (9): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (10): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (11): MultiHeadAttention(\n",
              "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm1): ModuleList(\n",
              "    (0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (4): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (6): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (7): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (8): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (10): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (11): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (ffns): ModuleList(\n",
              "    (0): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (1): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (2): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (3): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (4): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (5): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (6): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (7): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (8): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (9): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (10): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "    (11): TransformerFFN(\n",
              "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm2): ModuleList(\n",
              "    (0): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (4): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (6): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (7): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (8): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (10): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (11): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f60G-noq7NK"
      },
      "source": [
        "### Fonctions utilisées dans la boucle de constitution des embeddings des documents "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WN4-X3jsCQT"
      },
      "source": [
        "##### Création des blocs de texte\n",
        "###### Comme les sous-titres sont une liste de mots sans ponctuations, on peut se contenter d'un découpage à la hâche en blocs de taille égale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFWruCGqZ_am"
      },
      "source": [
        "# 6.c\n",
        "def decoupe_texte_en_blocs(texte, taille_bloc):\n",
        "\n",
        "  l_blocs_texte = []\n",
        "  # transformation du texte en liste de tokens bruts (pour le comptage des éléments du bloc, ce n'est pas la tokénization !!)\n",
        "  l_tokens_bruts_texte = texte.split()\n",
        "  nb_tokens_bruts = len(l_tokens_bruts_texte)\n",
        "  # nb de blocs\n",
        "  nb_blocs = nb_tokens_bruts // taille_bloc\n",
        "  if nb_tokens_bruts % taille_bloc != 0: nb_blocs += 1\n",
        "  # découpage\n",
        "  for no_bloc in range(nb_blocs):\n",
        "    l_tokens_bruts_bloc = l_tokens_bruts_texte[no_bloc * taille_bloc: min((no_bloc+1) * taille_bloc, nb_tokens_bruts)]\n",
        "    # avec remise sous forme de chaîne de caractères\n",
        "    bloc_texte = ' '.join(l_tokens_bruts_bloc)\n",
        "    l_blocs_texte.append(bloc_texte)\n",
        "\n",
        "  # on aura aussi besoin de faire une correspondance sommaire avec le texte lemmatisé et contenant les bigrammes et trigrammes\n",
        "  # le découpage en bloc pourra se mesurer en nombre de blocs avec partie décimale (réelle)\n",
        "  nb_blocs_dec = nb_tokens_bruts / taille_bloc\n",
        "\n",
        "  return l_blocs_texte, nb_blocs_dec "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOQyDQ0m2d_U"
      },
      "source": [
        "##### Calcul de l'embedding pour tous les blocs de texte d'un même texte général\n",
        "On prend ensuite la moyenne des embeddings des 4 dernières couches\n",
        "###### Si il y a trop de blocs dans un même batch cela prend toute la mémoire, on est donc contraint de découper la liste de blocs en plusieurs sous-listes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71HEMRXJZ_qO"
      },
      "source": [
        "# 6.d\n",
        "TAILLE_GROUPE_BLOCS = 16\n",
        "def calcule_embeddings(l_blocs_texte, tokeniseur, modele, nb_couches_moyennees=4):\n",
        "\n",
        "  # on renvoie une liste de np arrays, un par bloc de texte\n",
        "  l_embeddings_blocs = []\n",
        "  # pour chaque bloc de texte on récupére aussi le nb de tokens avant padding\n",
        "  l_nb_tokens = []\n",
        "\n",
        "  # découper la liste des blocs de texte en 1 ou N groupes de 16 blocs maxi\n",
        "  nb_blocs = len(l_blocs_texte)\n",
        "  nb_groupes_blocs = nb_blocs // TAILLE_GROUPE_BLOCS\n",
        "  if nb_blocs % TAILLE_GROUPE_BLOCS != 0: nb_groupes_blocs += 1\n",
        "\n",
        "  # boucler sur la liste des groupes de bloc\n",
        "  for no_groupe in range(nb_groupes_blocs):\n",
        "\n",
        "    # obtention des blocs de texte du groupe\n",
        "    l_blocs_texte_groupe = l_blocs_texte[no_groupe * TAILLE_GROUPE_BLOCS: min((no_groupe+1) * TAILLE_GROUPE_BLOCS, nb_blocs)]\n",
        "\n",
        "    # tokénisation de la liste des (blocs de) texte\n",
        "    l_blocs_tokenises_pt = tokeniseur(l_blocs_texte_groupe, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # récupérer le nb de tokens avant padding\n",
        "    for no_texte in range(len(l_blocs_texte_groupe)):\n",
        "      masque_attention = l_blocs_tokenises_pt['attention_mask'][no_texte]\n",
        "      nb_tokens_max = masque_attention.shape[0]\n",
        "      nb_tokens = 0\n",
        "      for m in range(nb_tokens_max):\n",
        "        if masque_attention[m] == 1: nb_tokens += 1\n",
        "        else: break\n",
        "      l_nb_tokens.append(nb_tokens)\n",
        "\n",
        "    # mettre en entrée les textes tokenizés, et récupérer la sortie\n",
        "    sorties = modele(**l_blocs_tokenises_pt)\n",
        "\n",
        "    # examen des couches cachées\n",
        "    sorties_transformers = sorties['hidden_states']\n",
        "\n",
        "    # concaténer toutes les couches\n",
        "    embeddings_tokens = torch.stack(sorties_transformers, dim=0)\n",
        "\n",
        "    # permuter les dimensions de façon à avoir l'ordre batch, tokens, couches et embeddings\n",
        "    embeddings_tokens = embeddings_tokens.permute(1, 2, 0, 3)\n",
        "\n",
        "    # on peut transformer le tout en numpy array\n",
        "    mx_embeddings_tokens = embeddings_tokens.cpu().detach().numpy()\n",
        "\n",
        "    # une stratégie classique est de moyenner les N dernières couches\n",
        "    # on suppose ici que le modèle BERT est moyen et non large (13 et non 25 couches)\n",
        "    ix_dernieres_couches = 13 - nb_couches_moyennees\n",
        "\n",
        "    # boucler texte par texte (sur la dimension batch)\n",
        "    nb_textes = mx_embeddings_tokens.shape[0]\n",
        "    for no_texte in range(nb_textes):\n",
        "\n",
        "      # extraire l'embedding du texte\n",
        "      mx_texte_embeddings_tokens = mx_embeddings_tokens[no_texte]\n",
        "\n",
        "      # sélection des dernières couches\n",
        "      mx_sel_N_dernieres_couches = mx_texte_embeddings_tokens[:, ix_dernieres_couches:, :]\n",
        "\n",
        "      # pour chaque token (1ère dimension) il faut sommer sur les N couches (2ème dimension), en gardant les embeddings (dernière dimension)\n",
        "      # les tokens sont alors en ligne, et les embeddings toujours en colonne\n",
        "      mx_somme_N_dernieres_couches = np.sum(mx_sel_N_dernieres_couches, axis=1)\n",
        "\n",
        "      # pour un embedding de sentence, on réduit encore en sommant sur l'axe 0 (celui des tokens, qu'on élimine)\n",
        "      # et on moyenne en tenant compte du nombre de tokens effectifs du texte\n",
        "      mx_moyenne_sur_bloc = np.sum(mx_somme_N_dernieres_couches, axis=0) / l_nb_tokens[no_texte]\n",
        "\n",
        "      # on peut récupérer l'embedding\n",
        "      l_embeddings_blocs.append(mx_moyenne_sur_bloc)\n",
        "\n",
        "  # on renvoie la liste des embeddings des blocs de texte, plus la liste des nb de tokens\n",
        "  return l_embeddings_blocs, l_nb_tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm7_xSAaVP4c"
      },
      "source": [
        "# 6.e\n",
        "# Eléments de dimensionnement\n",
        "NB_DIM_EMBEDDINGS = 768\n",
        "TAILLE_BLOC = 96\n",
        "NB_COUCHES = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s62srfvPIVNW"
      },
      "source": [
        "##### Créer les conteneurs suivants :\n",
        "- une matrice des embeddings (blocs de texte X dimensions d'embedding)\n",
        "- un dictionnaire faisant la correspondance entre blocs de textes et textes (avec position) et le dictionnaire inverse listant blocs du texte dans leur ordre (plus le nb réel/décimal de blocs pour découpage rapide)\n",
        "- une liste des nb de tokens des blocs de texte, et une approximation de leur contribution au textes dont ils sont issus "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-ZpZT2nkYco"
      },
      "source": [
        "###### Alors qu'il n'y a que 1342 sous-titres de vidéos, le tout prend 2 heures !!! - réduire à 300 vidéos..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ypKnFKblA_k"
      },
      "source": [
        "# df_docs = df_videos\n",
        "df_docs = df_videos.sample(300)\n",
        "df_docs.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv_9JxSyhF0U"
      },
      "source": [
        "# 6.f\n",
        "mx_blocs_embeddings = np.empty((0,NB_DIM_EMBEDDINGS))\n",
        "d_blocs_docs = {}\n",
        "d_docs_blocs = {}\n",
        "l_nb_tokens_blocs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjWd9_yQZ_6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea5144a-728f-464d-bc6b-46d6adef6e39"
      },
      "source": [
        "# 6.g\n",
        "# Création des conteneurs des blocs de texte\n",
        "\n",
        "no_bloc_corpus = 0\n",
        "\n",
        "for no_doc, doc in df_docs['texte_base'].iteritems():\n",
        "\n",
        "  # découpage du doc en blocs\n",
        "  l_blocs_doc, nb_blocs_dec = decoupe_texte_en_blocs(doc, TAILLE_BLOC)\n",
        "  nb_blocs = len(l_blocs_doc)\n",
        "  \n",
        "  # initialisation dic au niveau doc\n",
        "  d_docs_blocs[no_doc] = ([], nb_blocs_dec)\n",
        "\n",
        "  # obtention des embeddings\n",
        "  l_embeddings_blocs, l_nb_tokens = calcule_embeddings(l_blocs_doc, tokeniseur, modele, nb_couches_moyennees=NB_COUCHES)\n",
        "\n",
        "  # compléter éléments\n",
        "  for no_bloc_doc, embedding_bloc in enumerate(l_embeddings_blocs):\n",
        "\n",
        "    # bloc -> doc\n",
        "    d_blocs_docs[no_bloc_corpus] = (no_doc, no_bloc_doc)\n",
        "    # doc -> bloc\n",
        "    d_docs_blocs[no_doc][0].append(no_bloc_corpus)\n",
        "\n",
        "    # ajouter une ligne par bloc à la matrice bloc X embeddings\n",
        "    mx_blocs_embeddings = np.append(mx_blocs_embeddings, [embedding_bloc], axis=0)\n",
        "\n",
        "    # et nombre de tokens (au cas où)\n",
        "    l_nb_tokens_blocs.append(l_nb_tokens[no_bloc_doc])\n",
        "\n",
        "    no_bloc_corpus += 1\n",
        "\n",
        "  # avancement\n",
        "  if (no_doc+1) % 20 == 0: print(\"%d embeddings obtenus pour %d docs\" % (no_bloc_corpus, no_doc+1))\n",
        "\n",
        "# nombre total de blocs sur tout le corpus\n",
        "nb_bloc_corpus = no_bloc_corpus\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "240 embeddings obtenus pour 20 docs\n",
            "533 embeddings obtenus pour 40 docs\n",
            "960 embeddings obtenus pour 60 docs\n",
            "1123 embeddings obtenus pour 80 docs\n",
            "1771 embeddings obtenus pour 100 docs\n",
            "2341 embeddings obtenus pour 120 docs\n",
            "2664 embeddings obtenus pour 140 docs\n",
            "3040 embeddings obtenus pour 160 docs\n",
            "3233 embeddings obtenus pour 180 docs\n",
            "3552 embeddings obtenus pour 200 docs\n",
            "3830 embeddings obtenus pour 220 docs\n",
            "4304 embeddings obtenus pour 240 docs\n",
            "4460 embeddings obtenus pour 260 docs\n",
            "4648 embeddings obtenus pour 280 docs\n",
            "4945 embeddings obtenus pour 300 docs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ0CyrR5OGWm"
      },
      "source": [
        "##### Réduction de dimensionnalité des embeddings avant le clustering\n",
        "- le nombre de dimensions cible recommandé (BERTopic) est de 5, à ajuster selon le nombre de topics trouvé ultérieurement et la proportion de blocs non regroupés.\n",
        "- si le nombre de dimensions est trop élevé, il y a difficultés pour regrouper des documents (blocs) qui pourraient en fait l'être\n",
        "- si le nombre est trop faible, les topics ne sont pas assez discriminant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUflWfe7RXEC"
      },
      "source": [
        "# 6.h\n",
        "# Nous utilisons ici les paramètres choisis par BERTopic\n",
        "NB_VOISINS = 15\n",
        "#NB_DIMS_REDUITES = 5 # Il faut augmenter cette dimension pour obtenir un nombre raisonnable de topics\n",
        "NB_DIMS_REDUITES = 10\n",
        "DISTANCE_MIN = 0.0 # plutôt que 0.1\n",
        "METRIQUE_UMAP = 'cosine' # plutôt que 'euclidean'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_zi1a1qORbR"
      },
      "source": [
        "# 6.i\n",
        "reducteur_umap = umap.UMAP(n_neighbors=NB_VOISINS, min_dist=DISTANCE_MIN, n_components=NB_DIMS_REDUITES, metric=METRIQUE_UMAP)\n",
        "mx_blocs_reduite = reducteur_umap.fit_transform(mx_blocs_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdp9UiuxV_Td"
      },
      "source": [
        "##### Effectuer le regroupement par HDBScan\n",
        "- min_cluster_size : quelle est la taille minimum (nb de blocs) que doit avoir un cluster pour pouvoir exister ? Ce qui joue sur les décisions de séparation de clusters. Plus la taille est grande, moins il y aura de petits topics.\n",
        "- metric : 'euclidean' est la métrique par défaut. Pas de cosinus, car ne fait pas directement sens pour un algorithme de regroupement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6rx6MdVaALR"
      },
      "source": [
        "# 6.j\n",
        "# Nous utilisons ici les paramètres choisis par BERTopic\n",
        "TAILLE_MIN_TOPIC = 10\n",
        "METRIQUE_HDBSCAN = 'euclidean'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzDM0mUCaAZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b42a33-2b50-47d2-d876-35bbf839a8c0"
      },
      "source": [
        "# 6.k\n",
        "regroupeur_HDBSCAN = hdbscan.HDBSCAN(min_cluster_size=TAILLE_MIN_TOPIC, metric=METRIQUE_HDBSCAN)\n",
        "regroupeur_HDBSCAN.fit(mx_blocs_reduite)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HDBSCAN(algorithm='best', allow_single_cluster=False, alpha=1.0,\n",
              "        approx_min_span_tree=True, cluster_selection_epsilon=0.0,\n",
              "        cluster_selection_method='eom', core_dist_n_jobs=4,\n",
              "        gen_min_span_tree=False, leaf_size=40,\n",
              "        match_reference_implementation=False, memory=Memory(location=None),\n",
              "        metric='euclidean', min_cluster_size=10, min_samples=None, p=None,\n",
              "        prediction_data=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNr33KHHaA9G"
      },
      "source": [
        "###### Observation du nombre de clusters, et pour chacun de ses clusters, déterminer fiabilité moyenne d'apparetance (on pourrait également examiner distribution plus en profondeur)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5gO002vaApO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34ba1f3-135d-4516-bd3d-7068ffb83091"
      },
      "source": [
        "# 6.l\n",
        "# calcul du nb de topics\n",
        "# obtenir le nombre de groupes trouvés (de 0 à N)\n",
        "nb_topics = regroupeur_HDBSCAN.labels_.max() + 1\n",
        "# puis ajouter le pseudo-topic -1 (pas de regroupements)\n",
        "nb_topics += 1\n",
        "print(nb_topics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjgguueSJh1V"
      },
      "source": [
        "###### Par la suite, on va assigner au pseudo-topic le numéro et le label 0, et aux autres de 1 à N(+1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z35YgCu0aBa1"
      },
      "source": [
        "# 6.m\n",
        "# et créer la liste des nombres et probabilités de cluster\n",
        "d_topics = {}\n",
        "for no_topic, proba_topic in zip(regroupeur_HDBSCAN.labels_, regroupeur_HDBSCAN.probabilities_):\n",
        "  if (no_topic+1) not in d_topics:\n",
        "    d_topics[no_topic+1] = (1, proba_topic)\n",
        "  else:\n",
        "    d_topics[no_topic+1] = (d_topics[no_topic+1][0] + 1, d_topics[no_topic+1][1] + proba_topic)\n",
        "l_topics = []\n",
        "for no_topic, (nb_ds_topic, somme_proba_topics) in d_topics.items():\n",
        "  l_topics.append((no_topic, nb_ds_topic, somme_proba_topics / nb_ds_topic))\n",
        "# trier selon les numéros de topic\n",
        "l_topics.sort(key=lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XtGWYxMaBqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7278ed73-6b09-4084-858b-ba22bcf6ec99"
      },
      "source": [
        "# 6.n\n",
        "# examen rapide de la qualité des topics\n",
        "for topic in l_topics: print(topic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 2441, 0.0)\n",
            "(1, 20, 0.802483813494678)\n",
            "(2, 30, 0.6454298501062358)\n",
            "(3, 35, 0.6664792732456201)\n",
            "(4, 22, 0.6647984865142086)\n",
            "(5, 19, 0.7833656356532361)\n",
            "(6, 17, 0.8964217552682427)\n",
            "(7, 13, 0.9917366236666246)\n",
            "(8, 171, 0.5308227346807721)\n",
            "(9, 27, 0.7794319402976798)\n",
            "(10, 13, 0.9974776084717123)\n",
            "(11, 18, 0.9879106872021506)\n",
            "(12, 60, 0.6669152977076268)\n",
            "(13, 78, 0.4608623016653843)\n",
            "(14, 594, 0.912220027028298)\n",
            "(15, 20, 0.8659250898561552)\n",
            "(16, 10, 1.0)\n",
            "(17, 10, 1.0)\n",
            "(18, 11, 0.9998489602727753)\n",
            "(19, 22, 0.9062421448251108)\n",
            "(20, 18, 0.9408692247938366)\n",
            "(21, 13, 0.9946469041128272)\n",
            "(22, 11, 0.9996441862585947)\n",
            "(23, 12, 0.9922704358346186)\n",
            "(24, 12, 0.9959916489968107)\n",
            "(25, 27, 0.9292913742288037)\n",
            "(26, 10, 1.0)\n",
            "(27, 37, 0.9030926318251342)\n",
            "(28, 27, 0.9412274840974315)\n",
            "(29, 11, 0.9982169235329846)\n",
            "(30, 22, 0.8902069157749953)\n",
            "(31, 10, 1.0)\n",
            "(32, 45, 0.5017495210815157)\n",
            "(33, 64, 0.7110300243420653)\n",
            "(34, 15, 0.9875890275690898)\n",
            "(35, 11, 0.9988075745424979)\n",
            "(36, 13, 0.9954503936048403)\n",
            "(37, 61, 0.7311448419609906)\n",
            "(38, 56, 0.8728089630204886)\n",
            "(39, 39, 0.7504296827181454)\n",
            "(40, 15, 0.9852833277174398)\n",
            "(41, 55, 0.9561333190121654)\n",
            "(42, 29, 0.9792147708736517)\n",
            "(43, 18, 0.9562491273105798)\n",
            "(44, 23, 0.9012396746009685)\n",
            "(45, 15, 0.9606492233198718)\n",
            "(46, 107, 0.9807754974409448)\n",
            "(47, 20, 0.8868801604728004)\n",
            "(48, 35, 0.8362537063789907)\n",
            "(49, 11, 0.9981689328792963)\n",
            "(50, 10, 1.0)\n",
            "(51, 15, 0.9557795671388593)\n",
            "(52, 12, 0.9998630950897475)\n",
            "(53, 319, 0.9761627542521596)\n",
            "(54, 20, 0.9564875785301913)\n",
            "(55, 96, 0.9722246707711992)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOuA392fbim-"
      },
      "source": [
        "##### Création des matrices docs X topics et topics X termes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIT8xdENb1vj"
      },
      "source": [
        "###### Pour la matrice docs X topics, il faut pour chaque doc retrouver les topics de ses blocs de texte, et y associer les différents topics en tenant compte de la longueur des blocs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDE-6QtEaB5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a0b605-f12c-4ed8-87f0-c87959f0bf13"
      },
      "source": [
        "# 6.o\n",
        "mx_docs_topics = np.zeros((nb_docs, nb_topics))\n",
        "\n",
        "for no_doc, (l_blocs_doc, nb_blocs_dec) in d_docs_blocs.items():\n",
        "\n",
        "  mx_topics = np.zeros((nb_topics))\n",
        "  \n",
        "  # parcourir les blocs du doc\n",
        "  for no_bloc_doc, no_bloc_corpus in enumerate(l_blocs_doc):\n",
        "    # décalage de 1 pour sans topic à 0 et les autres à partir de 1\n",
        "    no_topic_bloc = regroupeur_HDBSCAN.labels_[no_bloc_corpus] + 1\n",
        "    proba_topic_bloc = regroupeur_HDBSCAN.probabilities_[no_bloc_corpus]\n",
        "    # poids du bloc, 1, sauf si dernier bloc avec résidus du découpage\n",
        "    poids_bloc = 1 if (no_bloc_doc + 1 < nb_blocs_dec) else (nb_blocs_dec - no_bloc_doc)\n",
        "    # incrémenter le poids du topic correspondant\n",
        "    # en fait, il peut arriver que tous les blocs d'un même doc aient une probabilité nulle,\n",
        "    # ne pas tenir compte de cette dernière, en tous cas si la somme est nulle, et\n",
        "    # en attendant, dans tous les cas de figure\n",
        "    #mx_topics[no_topic_bloc] += poids_bloc * proba_topic_bloc\n",
        "    mx_topics[no_topic_bloc] += poids_bloc\n",
        "\n",
        "  # normaliser tous les poids de façon à ce que la somme fasse 1\n",
        "  #somme_topics = np.sum(mx_topics)\n",
        "  somme_topics = nb_blocs_dec\n",
        "  #print(no_doc, somme_topics)\n",
        "  mx_topics = mx_topics / somme_topics\n",
        "  \n",
        "  # porter dans la matrice docs X topics\n",
        "  mx_docs_topics[no_doc] = mx_topics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.34375\n",
            "1 2.0416666666666665\n",
            "2 2.21875\n",
            "3 2.9791666666666665\n",
            "4 3.7916666666666665\n",
            "5 8.1875\n",
            "6 3.3854166666666665\n",
            "7 5.927083333333333\n",
            "8 1.4270833333333333\n",
            "9 12.197916666666666\n",
            "10 15.1875\n",
            "11 6.927083333333333\n",
            "12 29.385416666666668\n",
            "13 1.9479166666666667\n",
            "14 15.208333333333334\n",
            "15 29.8125\n",
            "16 61.947916666666664\n",
            "17 7.114583333333333\n",
            "18 1.75\n",
            "19 18.135416666666668\n",
            "20 2.6354166666666665\n",
            "21 18.0\n",
            "22 2.4166666666666665\n",
            "23 41.0\n",
            "24 18.833333333333332\n",
            "25 3.4479166666666665\n",
            "26 3.8541666666666665\n",
            "27 24.510416666666668\n",
            "28 2.375\n",
            "29 3.21875\n",
            "30 3.1875\n",
            "31 1.90625\n",
            "32 3.6145833333333335\n",
            "33 27.104166666666668\n",
            "34 2.03125\n",
            "35 5.291666666666667\n",
            "36 26.416666666666668\n",
            "37 45.020833333333336\n",
            "38 3.28125\n",
            "39 44.958333333333336\n",
            "40 4.875\n",
            "41 45.291666666666664\n",
            "42 2.90625\n",
            "43 35.3125\n",
            "44 3.1041666666666665\n",
            "45 78.02083333333333\n",
            "46 5.34375\n",
            "47 8.010416666666666\n",
            "48 48.75\n",
            "49 1.8333333333333333\n",
            "50 11.15625\n",
            "51 3.03125\n",
            "52 0.875\n",
            "53 18.739583333333332\n",
            "54 41.4375\n",
            "55 2.3854166666666665\n",
            "56 16.010416666666668\n",
            "57 72.72916666666667\n",
            "58 4.5625\n",
            "59 11.677083333333334\n",
            "60 3.0729166666666665\n",
            "61 9.8125\n",
            "62 0.84375\n",
            "63 4.291666666666667\n",
            "64 2.1666666666666665\n",
            "65 3.8541666666666665\n",
            "66 19.989583333333332\n",
            "67 18.0\n",
            "68 6.979166666666667\n",
            "69 2.53125\n",
            "70 1.6875\n",
            "71 5.979166666666667\n",
            "72 1.7708333333333333\n",
            "73 2.96875\n",
            "74 11.770833333333334\n",
            "75 5.59375\n",
            "76 21.041666666666668\n",
            "77 3.4375\n",
            "78 27.46875\n",
            "79 2.59375\n",
            "80 1.53125\n",
            "81 9.083333333333334\n",
            "82 8.875\n",
            "83 16.385416666666668\n",
            "84 24.260416666666668\n",
            "85 6.302083333333333\n",
            "86 2.3854166666666665\n",
            "87 1.6875\n",
            "88 12.020833333333334\n",
            "89 97.79166666666667\n",
            "90 83.36458333333333\n",
            "91 5.989583333333333\n",
            "92 2.25\n",
            "93 1.6145833333333333\n",
            "94 288.1041666666667\n",
            "95 2.5833333333333335\n",
            "96 3.3333333333333335\n",
            "97 45.854166666666664\n",
            "98 22.8125\n",
            "99 1.8229166666666667\n",
            "100 97.3125\n",
            "101 79.85416666666667\n",
            "102 91.39583333333333\n",
            "103 3.3020833333333335\n",
            "104 1.9479166666666667\n",
            "105 20.34375\n",
            "106 3.0729166666666665\n",
            "107 1.90625\n",
            "108 1.90625\n",
            "109 45.104166666666664\n",
            "110 11.958333333333334\n",
            "111 2.3541666666666665\n",
            "112 2.3541666666666665\n",
            "113 40.8125\n",
            "114 32.34375\n",
            "115 26.385416666666668\n",
            "116 6.5\n",
            "117 0.4375\n",
            "118 3.2708333333333335\n",
            "119 87.54166666666667\n",
            "120 8.833333333333334\n",
            "121 2.7291666666666665\n",
            "122 3.34375\n",
            "123 13.166666666666666\n",
            "124 3.3645833333333335\n",
            "125 12.885416666666666\n",
            "126 1.8645833333333333\n",
            "127 3.875\n",
            "128 33.645833333333336\n",
            "129 18.333333333333332\n",
            "130 2.8645833333333335\n",
            "131 4.25\n",
            "132 138.94791666666666\n",
            "133 15.947916666666666\n",
            "134 27.447916666666668\n",
            "135 2.3229166666666665\n",
            "136 2.9895833333333335\n",
            "137 12.28125\n",
            "138 2.7395833333333335\n",
            "139 3.28125\n",
            "140 2.3541666666666665\n",
            "141 20.96875\n",
            "142 13.052083333333334\n",
            "143 5.239583333333333\n",
            "144 249.16666666666666\n",
            "145 0.8541666666666666\n",
            "146 2.0416666666666665\n",
            "147 10.25\n",
            "148 2.65625\n",
            "149 1.0625\n",
            "150 2.1875\n",
            "151 25.447916666666668\n",
            "152 4.25\n",
            "153 2.0833333333333335\n",
            "154 1.7291666666666667\n",
            "155 2.0625\n",
            "156 1.8541666666666667\n",
            "157 8.739583333333334\n",
            "158 5.239583333333333\n",
            "159 2.375\n",
            "160 18.927083333333332\n",
            "161 3.625\n",
            "162 3.3020833333333335\n",
            "163 2.7604166666666665\n",
            "164 1.6666666666666667\n",
            "165 0.8229166666666666\n",
            "166 14.885416666666666\n",
            "167 10.666666666666666\n",
            "168 27.78125\n",
            "169 16.770833333333332\n",
            "170 0.78125\n",
            "171 2.0729166666666665\n",
            "172 1.8125\n",
            "173 3.03125\n",
            "174 3.25\n",
            "175 60.416666666666664\n",
            "176 3.125\n",
            "177 3.3958333333333335\n",
            "178 2.8333333333333335\n",
            "179 2.3020833333333335\n",
            "180 3.875\n",
            "181 1.9895833333333333\n",
            "182 2.1354166666666665\n",
            "183 173.63541666666666\n",
            "184 2.0729166666666665\n",
            "185 3.09375\n",
            "186 11.59375\n",
            "187 5.416666666666667\n",
            "188 46.302083333333336\n",
            "189 6.302083333333333\n",
            "190 3.21875\n",
            "191 3.7291666666666665\n",
            "192 6.1875\n",
            "193 12.177083333333334\n",
            "194 4.052083333333333\n",
            "195 2.8958333333333335\n",
            "196 1.8229166666666667\n",
            "197 1.1979166666666667\n",
            "198 3.0\n",
            "199 13.1875\n",
            "200 44.520833333333336\n",
            "201 12.135416666666666\n",
            "202 44.510416666666664\n",
            "203 23.822916666666668\n",
            "204 6.354166666666667\n",
            "205 5.75\n",
            "206 2.90625\n",
            "207 18.260416666666668\n",
            "208 1.9895833333333333\n",
            "209 3.0416666666666665\n",
            "210 3.1145833333333335\n",
            "211 21.385416666666668\n",
            "212 18.239583333333332\n",
            "213 2.3541666666666665\n",
            "214 1.1875\n",
            "215 4.458333333333333\n",
            "216 8.614583333333334\n",
            "217 10.927083333333334\n",
            "218 31.364583333333332\n",
            "219 2.7395833333333335\n",
            "220 4.822916666666667\n",
            "221 2.6666666666666665\n",
            "222 23.71875\n",
            "223 8.458333333333334\n",
            "224 2.40625\n",
            "225 3.84375\n",
            "226 82.45833333333333\n",
            "227 23.0625\n",
            "228 207.04166666666666\n",
            "229 7.479166666666667\n",
            "230 2.4375\n",
            "231 11.09375\n",
            "232 5.166666666666667\n",
            "233 9.583333333333334\n",
            "234 37.072916666666664\n",
            "235 2.6354166666666665\n",
            "236 1.2708333333333333\n",
            "237 14.9375\n",
            "238 5.885416666666667\n",
            "239 7.5625\n",
            "240 1.0729166666666667\n",
            "241 2.8645833333333335\n",
            "242 6.885416666666667\n",
            "243 3.0520833333333335\n",
            "244 3.0416666666666665\n",
            "245 2.2916666666666665\n",
            "246 20.083333333333332\n",
            "247 4.260416666666667\n",
            "248 15.479166666666666\n",
            "249 2.9270833333333335\n",
            "250 6.0\n",
            "251 28.520833333333332\n",
            "252 1.9895833333333333\n",
            "253 22.010416666666668\n",
            "254 6.59375\n",
            "255 5.15625\n",
            "256 1.8229166666666667\n",
            "257 1.7604166666666667\n",
            "258 2.9479166666666665\n",
            "259 7.104166666666667\n",
            "260 8.541666666666666\n",
            "261 3.3854166666666665\n",
            "262 20.927083333333332\n",
            "263 13.28125\n",
            "264 4.635416666666667\n",
            "265 6.302083333333333\n",
            "266 30.15625\n",
            "267 6.583333333333333\n",
            "268 13.791666666666666\n",
            "269 3.0520833333333335\n",
            "270 2.6666666666666665\n",
            "271 2.9166666666666665\n",
            "272 2.1041666666666665\n",
            "273 1.6979166666666667\n",
            "274 4.5625\n",
            "275 10.239583333333334\n",
            "276 2.7604166666666665\n",
            "277 33.447916666666664\n",
            "278 4.625\n",
            "279 2.4583333333333335\n",
            "280 16.9375\n",
            "281 5.927083333333333\n",
            "282 49.125\n",
            "283 7.53125\n",
            "284 26.614583333333332\n",
            "285 5.604166666666667\n",
            "286 5.5\n",
            "287 62.729166666666664\n",
            "288 3.3333333333333335\n",
            "289 8.0\n",
            "290 5.708333333333333\n",
            "291 2.1875\n",
            "292 6.6875\n",
            "293 16.697916666666668\n",
            "294 11.3125\n",
            "295 16.5\n",
            "296 6.833333333333333\n",
            "297 2.3645833333333335\n",
            "298 11.15625\n",
            "299 17.177083333333332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR5qh-5eRPXF"
      },
      "source": [
        "##### Pour la matrice topics X termes on procède comme BERTopic\n",
        "- on aggrège les textes des différents blocs appartenant à un même topic\n",
        "- on applique dessus une métrique c-Tf-Idf "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Xlluf-aoLe"
      },
      "source": [
        "###### Aggrégation des textes des différents blocs appartenant à un même topic\n",
        " - on utilise la colonne des textes réduits, lemmatisés et avec bigrammmes / trigrammes en faisant la supposition que le découpage en bloc est (quasiment) proportionnel entre texte de départ et texte lemmatisé\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7bGNd-0aCJO"
      },
      "source": [
        "# 6.p\n",
        "# on crée les listes de tokens associées à chaque topic, on les initialise à vide\n",
        "l_topics_l_tokens = []\n",
        "for no_topic in range(nb_topics):\n",
        "  l_topics_l_tokens.append([])\n",
        "\n",
        "# boucler sur les documents\n",
        "for no_doc, texte in df_docs['textes_sous_titres_avec_bigrammes'].iteritems():\n",
        "\n",
        "  # découper le texte selon les blocs\n",
        "  nb_blocs = len(d_docs_blocs[no_doc][0])\n",
        "  nb_blocs_dec = d_docs_blocs[no_doc][1]\n",
        "  l_tokens = texte.split()\n",
        "  nb_tokens = len(l_tokens)\n",
        "\n",
        "  # retrouver les blocs\n",
        "  taille_bloc = int(nb_tokens / nb_blocs_dec)\n",
        "  for no_bloc in range(nb_blocs):\n",
        "    # tokens du bloc\n",
        "    l_tokens_bloc = l_tokens[no_bloc * taille_bloc: min((no_bloc+1)* taille_bloc, nb_tokens)]\n",
        "    # topic du bloc\n",
        "    no_bloc_corpus = d_docs_blocs[no_doc][0][no_bloc]\n",
        "    no_topic = regroupeur_HDBSCAN.labels_[no_bloc_corpus] + 1 \n",
        "    # concaténation sur la liste générale des tokens du topic correspondant\n",
        "    l_topics_l_tokens[no_topic].extend(l_tokens_bloc) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuKhacKbHKow"
      },
      "source": [
        "# 6.q\n",
        "# comme on utilise le vectorisateur de scikit-learn, on va devoir transformer les listes de tokens en chaînes de caractère\n",
        "l_topics_l_textes = []\n",
        "for no_topic in range(nb_topics):\n",
        "  l_topics_l_textes.append(' '.join(l_topics_l_tokens[no_topic]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwGPIB9brz3a"
      },
      "source": [
        "###### Métrique c-tf-idf : analogue au calcul de tf-idf mais sur autant de documents que de topics.\n",
        "Cependant: \n",
        "1) dans tf on normalise la fréquence en la divisant par le nombre de tokens dans le document (le topic)\n",
        "2) dans idf, on considère non le nombre de documents / topics, mais le nombre de documents d'origine (de blocs), et qu'on divise non par le nombre de document dans lesquels les termes apparaissent mais par la fréquence totale du terme dans l'ensemble des documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMP8RrWxGWXw"
      },
      "source": [
        "# 6.r\n",
        "# sélection des termes dans les bonnes fréquences et dans les bon nombres\n",
        "MAX_DFREQ = 0.95\n",
        "MIN_DFREQ = 5\n",
        "NB_TOTAL_TERMES = 10000\n",
        "\n",
        "# et comme le travail de split a été effectué, surcharger le tokénisateur par défaut avec un split simple\n",
        "def simple_split(s):\n",
        "  return s.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h37WSgGKaCZ-"
      },
      "source": [
        " # 6.s\n",
        " # travailler à partir d'une matrice des comptages\n",
        " # on va éliminer comme à l'habitude les termes les plus fréquents et les plus rares, \n",
        " # et garder un nombre de termes raisonnable \n",
        " freqs = CountVectorizer(max_df=MAX_DFREQ, min_df=MIN_DFREQ, max_features=NB_TOTAL_TERMES, \n",
        "                         tokenizer=simple_split)\n",
        "\n",
        " # vectorisation, matrice topics X termes          \n",
        " mx_f_topics_termes = freqs.fit_transform(l_topics_l_textes)\n",
        " ix_termes = freqs.get_feature_names()\n",
        " nb_termes = len(ix_termes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA955tlgaCpY"
      },
      "source": [
        "# 6.t\n",
        "# adapter la matrice pour en faire une matrice c-tf-idf\n",
        "\n",
        "# il y a besoin pour chaque topic de la somme des fréquences de tous les termes\n",
        "mx_freq_topics = np.zeros((nb_topics))\n",
        "for no_topic in range(nb_topics):\n",
        "  mx_freq_topics[no_topic] = len(l_topics_l_tokens[no_topic])\n",
        "\n",
        "# et pour chaque terme de la somme de ses fréquences sur tous les topics\n",
        "mx_freq_termes = np.zeros((nb_termes))\n",
        "for no_terme in range(nb_termes):\n",
        "  mx_freq_termes[no_terme] = mx_f_topics_termes[:,no_terme].sum()\n",
        "\n",
        "# d'où la matrice définitive\n",
        "mx_topics_termes = np.zeros((nb_topics, nb_termes))\n",
        "for no_topic in range(nb_topics):\n",
        "  for no_terme in range(nb_termes):\n",
        "      tf = mx_f_topics_termes[no_topic, no_terme] / mx_freq_topics[no_topic]\n",
        "      idf = math.log(nb_bloc_corpus / mx_freq_termes[no_terme],2)\n",
        "      mx_topics_termes[no_topic, no_terme] = tf * idf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QF6BdsuOKPh"
      },
      "source": [
        "#### On a maintenant les éléments nécessaires pour faire des analyses de topics\n",
        "###### On va se contenter de lister les topics et leurs termes les plus importants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG5PNGScaC6R"
      },
      "source": [
        "# 7.a\n",
        "# trouver la liste des top termes (plus leurs poids) d'un topic\n",
        "def topic_top_termes(mx_topics_termes, ix_termes, no_topic, nb_top_termes):\n",
        "  v_topic_termes = mx_topics_termes[no_topic]    \n",
        "  return [(ix_termes[no_terme], v_topic_termes[no_terme])\\\n",
        "          for no_terme in np.argsort(v_topic_termes)[:-nb_top_termes-1:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyJyv8nDaDJP"
      },
      "source": [
        "# 7.b\n",
        "# trouver la liste des top docs (plus leurs poids) d'un topic\n",
        "def topic_top_docs(mx_docs_topics, no_topic, nb_top_docs):\n",
        "  v_topic_docs = mx_docs_topics[:,no_topic]    \n",
        "  return [(no_doc, v_topic_docs[no_doc])\\\n",
        "          for no_doc in np.argsort(v_topic_docs)[:-nb_top_docs-1:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WukdhOQOaDZH"
      },
      "source": [
        "# 7.c\n",
        "# trouver la masse totale sur les docs d'un topic\n",
        "def topic_masse_totale(mx_docs_topics, no_topic):\n",
        "  return mx_docs_topics[:,no_topic].sum() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPVd9aoxaDoW"
      },
      "source": [
        "# 7.d\n",
        "# dériver certaines informations sur le modèle de topics\n",
        "def informations_derivees(mx_docs_topics, mx_topics_termes):\n",
        "\n",
        "  # liste des topics avec un nom parlant dérivé des noms des termes les plus représentatifs,\n",
        "  # plus le poids des topics \n",
        "  nb_topics = mx_topics_termes.shape[0]\n",
        "  l_topics = []\n",
        "  for no_topic in range(nb_topics):\n",
        "    topic_attributs = {}\n",
        "    top_2_termes = topic_top_termes(mx_topics_termes, ix_termes, no_topic, 2)\n",
        "    topic_attributs['nom'] = \"%s %s\" % (top_2_termes[0][0], top_2_termes[1][0])\n",
        "    topic_attributs['masse'] = topic_masse_totale(mx_docs_topics, no_topic)\n",
        "    l_topics.append(topic_attributs)\n",
        "\n",
        "  return l_topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-a1bZlrOv0f"
      },
      "source": [
        "# 7.e\n",
        "l_topics = informations_derivees(mx_docs_topics, mx_topics_termes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAXCYA1hOwGA"
      },
      "source": [
        "# 7.f\n",
        "# liste textuelle des topics\n",
        "def montre_liste_topics(l_topics, mx_topics_termes, ix_termes,  \n",
        "                        nb_top_termes=10, avec_masses_topics=False, avec_masses_termes=False):\n",
        "        \n",
        "  for no_topic in range(len(l_topics)):\n",
        "\n",
        "    # topic en tant que tel\n",
        "    s_nom_topic = \"%d - %s\" % (no_topic+1, l_topics[no_topic]['nom'])\n",
        "    s_masse_topic = \"\"\n",
        "    if avec_masses_topics == True:\n",
        "      s_masse_topic = \" (masse %.3f)\" % (l_topics[no_topic]['masse'])\n",
        "    s_topic = \"%s%s : \" % (s_nom_topic, s_masse_topic)\n",
        "        \n",
        "    # et les N top termes\n",
        "    s_top_termes = \"\"\n",
        "    top_termes = topic_top_termes(mx_topics_termes, ix_termes, no_topic, nb_top_termes)\n",
        "    for ix, (terme, masse) in enumerate(top_termes):\n",
        "      s_masse_terme = \"\"\n",
        "      if avec_masses_termes == True:\n",
        "        s_masse_terme = \": %.3f\" % masse\n",
        "      s_sep_terme = \", \"\n",
        "      if ix == nb_top_termes - 1: s_sep_terme = \"\"\n",
        "      s_top_termes += \"%s%s%s\" % (terme, s_masse_terme, s_sep_terme) \n",
        "        \n",
        "    # sortie finale\n",
        "    print(\"%s%s\" % (s_topic, s_top_termes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y4KvATGOwV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe79412-d37b-4798-d676-ac49700c400c"
      },
      "source": [
        "# 7.g\n",
        "montre_liste_topics(l_topics, mx_topics_termes, ix_termes, \n",
        "                    nb_top_termes=10, avec_masses_topics=True, avec_masses_termes=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - yer faire (masse 132.173) : yer, faire, vouloir, dire, voir, savoir, pouvoir, aller, chose, prendre\n",
            "2 - candidat tour (masse 2.258) : candidat, tour, écologiste, socialiste, alliance, tête, verts, abstention, liste, voix\n",
            "3 - martine tribunal (masse 1.406) : martine, tribunal, mourir, homme, ferme, fou, of, invisible, auteur, offre\n",
            "4 - immobilier crédit (masse 4.772) : immobilier, crédit, fin, revenu, britannique, occasion, pourcent, marché, déficit, crise\n",
            "5 - joueur club (masse 5.218) : joueur, club, match, saison, lens, championnat, om, jouer, reporter, stade\n",
            "6 - application téléphone (masse 2.799) : application, téléphone, installer, apple, antoine, télécharger, montre, analyser, automatiquement, nouveau\n",
            "7 - indépendance solidaire (masse 1.185) : indépendance, solidaire, bâtir, nation, européen, écologique, nom, priorité, souffrir, mieux\n",
            "8 - compte banque (masse 0.714) : compte, banque, dédier, professionnel, activité, indépendant, bancaire, législatif, obligatoire, recours\n",
            "9 - vidéo partager (masse 5.874) : vidéo, partager, aller, jour, faire, chaîne, espérer, petit, direct, youtube\n",
            "10 - dette bce (masse 1.631) : dette, bce, banque_centrale, état, taux_intérêt, banque, marché, actif, payer, jamais\n",
            "11 - régime exception (masse 0.599) : régime, exception, emprunt, état_urgence, liberté, généraliser, état, voiture, corée_nord, habitude\n",
            "12 - allemagne plan_relance (masse 0.599) : allemagne, plan_relance, investissement, européen, fonds, tribunal, euro, défaut, plan, 750_milliard\n",
            "13 - action bourse (masse 2.051) : action, bourse, banque_centrale, actionnaire, apple, argent, milliard_dollar, banque, pourcent, acheter\n",
            "14 - turc turquie (masse 2.632) : turc, turquie, israélien, libye, israël, arabe, puissance, grec, grèce, militaire\n",
            "15 - jour pays (masse 78.698) : jour, pays, chine, france, paris, semaine, personne, devoir, an, cas\n",
            "16 - marché confinement (masse 1.374) : marché, confinement, vague, fortement, remonter, liquidité, regarde, récession, finalement, vent\n",
            "17 - plage minute (masse 1.117) : plage, minute, réserver, cellule, venir, salle, entraîner, sport, isolement, art\n",
            "18 - hôpital patient (masse 0.520) : hôpital, patient, cancer, poste, service, opérer, consultation, supprimer, fermer, dépistage\n",
            "19 - financier euro (masse 1.424) : financier, euro, réfléchir, yer, gouvernement, calmer, meurtre, marche, abri, expertise\n",
            "20 - sanction condamner (masse 0.789) : sanction, condamner, pénal, contenu, ministre, police, ordre_médecins, violences_policières, justice, exercer\n",
            "21 - masque complotiste (masse 0.751) : masque, complotiste, stock, octobre, semaine, masse, jour, midi, voir, épidémie\n",
            "22 - état économique (masse 0.097) : état, économique, délégué, existe, argent, chèque, gros, priver, lait, times\n",
            "23 - télétravail ennemi (masse 0.629) : télétravail, ennemi, femme, tire, place, europe, science, avancer, choisir, parole\n",
            "24 - école enfant (masse 0.863) : école, enfant, fournir, obliger, employeur, obligatoire, refuser, télétravail, parent, salarié\n",
            "25 - emploi financement (masse 1.656) : emploi, financement, chômage_partiel, corse, boîte, euro, entreprise, départ, évoquer, effectif\n",
            "26 - chômage travail (masse 0.982) : chômage, travail, revenu, ménage, lieu, ceterer, espace, enjeu, distance, travailler\n",
            "27 - étudiant payer (masse 1.075) : étudiant, payer, euro, école, coup, demande, yer, avancer, chèque, devoir\n",
            "28 - virus jour (masse 2.690) : virus, jour, france, épidémie, vague, cas, modèle, yer, région, tester\n",
            "29 - dégager responsable (masse 1.200) : dégager, responsable, coupable, vouloir, enfant, prendre, savoir, attendre, soigner, grève\n",
            "30 - rumeur délire (masse 0.079) : rumeur, délire, délirant, extrêmement, collectif, langage, grippe, danse, affirme, décrire\n",
            "31 - virus charge_virale (masse 2.940) : virus, charge_virale, coronavirus, grossesse, atteindre, maladie, bébé, risque, test_pcr, contagieux\n",
            "32 - système_immunitaire corps (masse 0.230) : système_immunitaire, corps, bon, main, parler, entretenir, bonne_santé, combattre, confiner, vaccin\n",
            "33 - masque surface (masse 2.636) : masque, surface, porter_masque, nez, tissu, laver, masque_chirurgical, enlever, mettre, visage\n",
            "34 - humanité monde (masse 1.541) : humanité, monde, virus, vouloir, peuple, capable, pouvoir, servir, vie, gouvernement\n",
            "35 - union récupérer (masse 0.358) : union, récupérer, chose, tension, sol, chinois, rencontrer, sortir, france, venir\n",
            "36 - génocide vérité (masse 0.329) : génocide, vérité, chercheur, effectivement, science, histoire, rythme, politique, question, lire\n",
            "37 - contacter distance (masse 1.391) : contacter, distance, tester, langue, habitude, étudiant, régulièrement, cinéma, masque, fois\n",
            "38 - audition ehpad (masse 2.838) : audition, ehpad, monsieur_président, ordre, question, relever, intérêt, effectivement, prise_en_charge, protocole\n",
            "39 - débat etats_unis (masse 1.826) : débat, etats_unis, opposition, politique, écologie, complètement, gauche, question, idée, problème\n",
            "40 - gauche républicain (masse 1.642) : gauche, républicain, candidat, donald_trump, démocrate, élection_présidentiel, politique, occasion, etats_unis, finalement\n",
            "41 - verts liste (masse 0.689) : verts, liste, ville, michel, parti, printemps, candidat, droite, rassemblement, erreur\n",
            "42 - kinésithérapeute effectivement (masse 0.833) : kinésithérapeute, effectivement, santé, recommandation, exprimer, patient, ehpad, savoir, mars, février\n",
            "43 - mars établissement (masse 0.371) : mars, établissement, expérience, chose, monsieur, évoquer, équipe, moment, effectivement, canicule\n",
            "44 - pharmacien professionnel_santé (masse 0.085) : pharmacien, professionnel_santé, santé_publique, difficulté, exercer, publier, rappel, prendre_en_charge, masque, kinésithérapeute\n",
            "45 - second_tour tour (masse 1.597) : second_tour, tour, organiser, reporter, scrutin, élection, commune, électeur, municipal, élections_municipales\n",
            "46 - corse investissement (masse 0.242) : corse, investissement, accompagner, crédit, état, secteur, sujet, île, matière, transfert\n",
            "47 - marseille page (masse 3.369) : marseille, page, médecin, euro, rappeler, apprendre, france, président, professeur, dénoncer\n",
            "48 - agent employeur (masse 0.834) : agent, employeur, activité, public, service, présence, ministère, fois, télétravail, évidemment\n",
            "49 - social mobiliser (masse 3.137) : social, mobiliser, période, parlement, engagement, contrôle, jeudi, économique, mesure, frontière\n",
            "50 - prendre_décision solidarité (masse 1.104) : prendre_décision, solidarité, proche, compatriote, rester, solidaire, nouveau, scientifique, devoir, être\n",
            "51 - journaliste dire (masse 0.131) : journaliste, dire, 2, rédaction, complotisme, france, colle, islamiste, folie, ultra\n",
            "52 - média poser_question (masse 0.206) : média, poser_question, vaccin, demander, solution, nombre_cas, vitamine, rapport, jamais, pouvoir\n",
            "53 - peur prendre (masse 0.212) : peur, prendre, marseille, france, civil, jour, yer, prise, former, cas\n",
            "54 - savoir vouloir (masse 6.862) : savoir, vouloir, dire, voir, faire, aller, petit, vrai, an, connaître\n",
            "55 - étude opinion (masse 0.816) : étude, opinion, utiliser, montre, mortalité, toxique, lire, traitement, chloroquine, publier\n",
            "56 - virus positif (masse 5.927) : virus, positif, tester, test, médicament, étude, voir, patient, sida, mortalité\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}